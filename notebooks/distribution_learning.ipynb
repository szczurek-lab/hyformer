{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run Distribution Learning Benchmark"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b26dcdcd117802dc"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adam/Projects/hybrid-transformer\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T12:35:20.028665586Z",
     "start_time": "2023-12-27T12:35:20.028090764Z"
    }
   },
   "id": "422d4f35c0246db1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import wandb\n",
    "\n",
    "from hybrid_transformer.configs.task import TaskConfig\n",
    "from hybrid_transformer.configs.model import ModelConfig\n",
    "from hybrid_transformer.configs.trainer import TrainerConfig\n",
    "from hybrid_transformer.configs.logger import LoggerConfig\n",
    "\n",
    "from hybrid_transformer.utils.datasets.auto import AutoDataset\n",
    "from hybrid_transformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from hybrid_transformer.models.auto import AutoModel\n",
    "from hybrid_transformer.utils.loggers.wandb import WandbLogger\n",
    "\n",
    "from hybrid_transformer.trainers.trainer import Trainer\n",
    "\n",
    "from scripts.train import DEFAULT_CONFIG_FILES\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T12:35:24.635028711Z",
     "start_time": "2023-12-27T12:35:24.604773182Z"
    }
   },
   "id": "388ac09832efcd15"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type GPT to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n"
     ]
    }
   ],
   "source": [
    "task_config = TaskConfig.from_pretrained(DEFAULT_CONFIG_FILES['task'])\n",
    "model_config = ModelConfig.from_pretrained(DEFAULT_CONFIG_FILES['model'])\n",
    "# model_config.model_type = 'HybridTransformer'\n",
    "# model_config.task_p = 0.95\n",
    "trainer_config = TrainerConfig.from_pretrained(DEFAULT_CONFIG_FILES['trainer'])\n",
    "logger_config = LoggerConfig.from_pretrained(DEFAULT_CONFIG_FILES['logger'])\n",
    "task_config.validate = False\n",
    "logger_config.wandb_log = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T12:39:44.973854828Z",
     "start_time": "2023-12-27T12:39:44.943926499Z"
    }
   },
   "id": "ea1ae3c22872b6df"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelConfig' object has no attribute 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m dataset \u001B[38;5;241m=\u001B[39m AutoDataset\u001B[38;5;241m.\u001B[39mfrom_config(task_config)\n\u001B[1;32m      2\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m AutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_config(task_config)\n\u001B[0;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m logger \u001B[38;5;241m=\u001B[39m WandbLogger(logger_config, [task_config, model_config, trainer_config])\n\u001B[1;32m      5\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(config\u001B[38;5;241m=\u001B[39mtrainer_config, model\u001B[38;5;241m=\u001B[39mmodel, train_dataset\u001B[38;5;241m=\u001B[39mdataset, eval_dataset\u001B[38;5;241m=\u001B[39mdataset, tokenizer\u001B[38;5;241m=\u001B[39mtokenizer, logger\u001B[38;5;241m=\u001B[39mlogger)\n",
      "File \u001B[0;32m~/Projects/hybrid-transformer/hybrid_transformer/models/auto.py:11\u001B[0m, in \u001B[0;36mAutoModel.from_config\u001B[0;34m(cls, config)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_config\u001B[39m(\u001B[38;5;28mcls\u001B[39m, config: ModelConfig):\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_name\u001B[49m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPT\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBERT\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHybridTransformer\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`model_name` must be \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPT\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBERT\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHybridTransformer\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mmodel_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGPT\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/hybrid-transformer/lib/python3.11/site-packages/transformers/configuration_utils.py:265\u001B[0m, in \u001B[0;36mPretrainedConfig.__getattribute__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattribute_map\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattribute_map\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    264\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattribute_map\u001B[39m\u001B[38;5;124m\"\u001B[39m)[key]\n\u001B[0;32m--> 265\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'ModelConfig' object has no attribute 'model_name'"
     ]
    }
   ],
   "source": [
    "dataset = AutoDataset.from_config(task_config)\n",
    "tokenizer = AutoTokenizer.from_config(task_config)\n",
    "model = AutoModel.from_config(model_config)\n",
    "logger = WandbLogger(logger_config, [task_config, model_config, trainer_config])\n",
    "trainer = Trainer(config=trainer_config, model=model, train_dataset=dataset, eval_dataset=dataset, tokenizer=tokenizer, logger=logger)\n",
    "# trainer.load_checkpoint()\n",
    "trainer.compile = False\n",
    "trainer._train_init()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T13:31:12.252167452Z",
     "start_time": "2023-12-27T13:31:11.923725991Z"
    }
   },
   "id": "b6acebc3b3f46dc4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 63, with 38,115,840 parameters\n",
      "num non-decayed parameter tensors: 25, with 12,800 parameters\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/hybrid-transformer/hybrid_transformer/trainers/trainer.py:281\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_init()\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39minit_run()\n\u001B[0;32m--> 281\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m()\n\u001B[1;32m    283\u001B[0m task \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlm\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    284\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_batch(split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, task\u001B[38;5;241m=\u001B[39mtask)  \u001B[38;5;66;03m# fetch the very first batch\u001B[39;00m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'function' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T12:36:13.669306624Z",
     "start_time": "2023-12-27T12:36:13.241076232Z"
    }
   },
   "id": "f049ad40324d2d47"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "OptimizedModule(\n  (_orig_mod): GPT(\n    (transformer): ModuleDict(\n      (wte): Embedding(588, 512)\n      (wpe): Embedding(128, 512)\n      (drop): Dropout(p=0.1, inplace=False)\n      (h): ModuleList(\n        (0-11): 12 x HybridTransformerBlock(\n          (ln_1): LayerNorm()\n          (attn_1): HybridSelfAttention(\n            (q_proj): Linear(in_features=512, out_features=512, bias=False)\n            (kv_proj): Linear(in_features=512, out_features=1024, bias=False)\n            (out_proj): Linear(in_features=512, out_features=512, bias=False)\n            (attn_dropout): Dropout(p=0.1, inplace=False)\n            (resid_dropout): Dropout(p=0.1, inplace=False)\n          )\n          (ln_2): LayerNorm()\n          (mlp): MLP(\n            (fc): Linear(in_features=512, out_features=2048, bias=False)\n            (gelu): GELU(approximate='none')\n            (proj): Linear(in_features=2048, out_features=512, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (ln_f): LayerNorm()\n    )\n    (lm_head): Linear(in_features=512, out_features=588, bias=False)\n    (prediction_head): Linear(in_features=512, out_features=1, bias=False)\n  )\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T12:40:16.775739719Z",
     "start_time": "2023-12-27T12:40:16.746076330Z"
    }
   },
   "id": "80b426c88287bec1"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.task_p"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T12:39:58.894531978Z",
     "start_time": "2023-12-27T12:39:58.741020942Z"
    }
   },
   "id": "8c27c4451764bd57"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.is_ddp_run"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T13:02:36.397550473Z",
     "start_time": "2023-12-27T13:02:36.309779711Z"
    }
   },
   "id": "fdf6f7e3809d8ee2"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'model_type': '',\n 'embedding_dim': 512,\n 'num_heads': 8,\n 'num_layers': 12,\n 'bias': False,\n 'dropout': 0.1,\n 'layer_norm_eps': 1e-05,\n 'block_size': 1024,\n 'vocab_size': 588,\n 'max_seq_len': 128,\n 'return_dict': True,\n 'output_hidden_states': False,\n 'output_attentions': False,\n 'torchscript': False,\n 'torch_dtype': None,\n 'use_bfloat16': False,\n 'tf_legacy_loss': False,\n 'pruned_heads': {},\n 'tie_word_embeddings': True,\n 'is_encoder_decoder': False,\n 'is_decoder': False,\n 'cross_attention_hidden_size': None,\n 'add_cross_attention': False,\n 'tie_encoder_decoder': False,\n 'max_length': 20,\n 'min_length': 0,\n 'do_sample': False,\n 'early_stopping': False,\n 'num_beams': 1,\n 'num_beam_groups': 1,\n 'diversity_penalty': 0.0,\n 'temperature': 1.0,\n 'top_k': 50,\n 'top_p': 1.0,\n 'typical_p': 1.0,\n 'repetition_penalty': 1.0,\n 'length_penalty': 1.0,\n 'no_repeat_ngram_size': 0,\n 'encoder_no_repeat_ngram_size': 0,\n 'bad_words_ids': None,\n 'num_return_sequences': 1,\n 'chunk_size_feed_forward': 0,\n 'output_scores': False,\n 'return_dict_in_generate': False,\n 'forced_bos_token_id': None,\n 'forced_eos_token_id': None,\n 'remove_invalid_values': False,\n 'exponential_decay_length_penalty': None,\n 'suppress_tokens': None,\n 'begin_suppress_tokens': None,\n 'architectures': None,\n 'finetuning_task': None,\n 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'},\n 'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n 'tokenizer_class': None,\n 'prefix': None,\n 'bos_token_id': None,\n 'pad_token_id': None,\n 'eos_token_id': None,\n 'sep_token_id': None,\n 'decoder_start_token_id': None,\n 'task_specific_params': None,\n 'problem_type': None,\n '_name_or_path': '',\n 'transformers_version': '4.36.1',\n 'task_p': None}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.to_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T13:03:33.957961791Z",
     "start_time": "2023-12-27T13:03:33.929876808Z"
    }
   },
   "id": "36d30a66005926f5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
