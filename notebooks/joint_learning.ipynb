{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Run Joint Learning Benchmark"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b26dcdcd117802dc"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/adam/Projects/hybrid-transformer\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:08:59.000018284Z",
     "start_time": "2024-01-04T17:08:58.999261435Z"
    }
   },
   "id": "422d4f35c0246db1"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from hybrid_transformer.configs.task import TaskConfig\n",
    "from hybrid_transformer.configs.model import ModelConfig\n",
    "from hybrid_transformer.configs.trainer import TrainerConfig\n",
    "from hybrid_transformer.configs.logger import LoggerConfig\n",
    "\n",
    "from hybrid_transformer.utils.datasets.auto import AutoDataset\n",
    "from hybrid_transformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from hybrid_transformer.models.auto import AutoModel\n",
    "from hybrid_transformer.utils.loggers.wandb import WandbLogger\n",
    "\n",
    "from hybrid_transformer.trainers.trainer import Trainer\n",
    "\n",
    "from scripts.pretrain.train import DEFAULT_CONFIG_FILES\n",
    "\n",
    "from hybrid_transformer.utils.objectives.guacamol.objective import GUACAMOL_TASKS\n",
    "from hybrid_transformer.models.prediction import PREDICTION_MODEL_CONFIGS\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:09:42.567560365Z",
     "start_time": "2024-01-04T17:09:42.524541945Z"
    }
   },
   "id": "388ac09832efcd15"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/adam/miniconda3/envs/hybrid-transformer/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
      "Downloading lipo MoleculeNet task...\n",
      "Random seed set to 0\n",
      "Downloaded into ./data/molecule_net/lipo\n",
      "Loaded lipo data.\n",
      "number of parameters: 38.06M\n",
      "tokens per iteration will be: 512\n",
      "Using cuda device\n",
      "Random seed set to 1337\n",
      "num decayed parameter tensors: 63, with 38,115,840 parameters\n",
      "num non-decayed parameter tensors: 25, with 12,800 parameters\n",
      "using fused AdamW: True\n",
      "Compiling model..\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:s9ko5n3s) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">GPTForPrediction_zaleplon</strong> at: <a href='https://wandb.ai/adam-izdebski/debug/runs/s9ko5n3s' target=\"_blank\">https://wandb.ai/adam-izdebski/debug/runs/s9ko5n3s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20240104_180946-s9ko5n3s/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:s9ko5n3s). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.1"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/adam/Projects/hybrid-transformer/wandb/run-20240104_181102-n8wd53do</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/adam-izdebski/debug/runs/n8wd53do' target=\"_blank\">GPTForPrediction_lipo</a></strong> to <a href='https://wandb.ai/adam-izdebski/debug' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/adam-izdebski/debug' target=\"_blank\">https://wandb.ai/adam-izdebski/debug</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/adam-izdebski/debug/runs/n8wd53do' target=\"_blank\">https://wandb.ai/adam-izdebski/debug/runs/n8wd53do</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 38.06M\n",
      "tokens per iteration will be: 512\n",
      "Using cuda device\n",
      "Random seed set to 1337\n",
      "num decayed parameter tensors: 63, with 38,115,840 parameters\n",
      "num non-decayed parameter tensors: 25, with 12,800 parameters\n",
      "using fused AdamW: True\n",
      "Compiling model..\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:n8wd53do) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">GPTForPrediction_lipo</strong> at: <a href='https://wandb.ai/adam-izdebski/debug/runs/n8wd53do' target=\"_blank\">https://wandb.ai/adam-izdebski/debug/runs/n8wd53do</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20240104_181102-n8wd53do/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:n8wd53do). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.1"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/adam/Projects/hybrid-transformer/wandb/run-20240104_181238-4s228u6d</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/adam-izdebski/debug/runs/4s228u6d' target=\"_blank\">JointGPT_lipo</a></strong> to <a href='https://wandb.ai/adam-izdebski/debug' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/adam-izdebski/debug' target=\"_blank\">https://wandb.ai/adam-izdebski/debug</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/adam-izdebski/debug/runs/4s228u6d' target=\"_blank\">https://wandb.ai/adam-izdebski/debug/runs/4s228u6d</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 36\u001B[0m\n\u001B[1;32m     33\u001B[0m logger \u001B[38;5;241m=\u001B[39m WandbLogger(logger_config, [task_config, model_config, trainer_config])\n\u001B[1;32m     34\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(config\u001B[38;5;241m=\u001B[39mtrainer_config, model\u001B[38;5;241m=\u001B[39mmodel, train_dataset\u001B[38;5;241m=\u001B[39mdataset, eval_dataset\u001B[38;5;241m=\u001B[39mdataset, tokenizer\u001B[38;5;241m=\u001B[39mtokenizer, logger\u001B[38;5;241m=\u001B[39mlogger)\n\u001B[0;32m---> 36\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/hybrid-transformer/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Projects/hybrid-transformer/hybrid_transformer/trainers/trainer.py:359\u001B[0m, in \u001B[0;36mTrainer.test\u001B[0;34m(self, dataset)\u001B[0m\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mctx:\n\u001B[1;32m    355\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\n\u001B[1;32m    356\u001B[0m             task\u001B[38;5;241m=\u001B[39mtask, input_ids\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m], attention_mask\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m    357\u001B[0m             labels\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m], target\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m], eos_mask\u001B[38;5;241m=\u001B[39minputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meos_mask\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m--> 359\u001B[0m     predictions\u001B[38;5;241m.\u001B[39mextend(dataset\u001B[38;5;241m.\u001B[39mundo_target_transform(\u001B[43moutputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m))\n\u001B[1;32m    360\u001B[0m     targets\u001B[38;5;241m.\u001B[39mextend(dataset\u001B[38;5;241m.\u001B[39mundo_target_transform(inputs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mcpu()))\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m predictions, targets\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Load configs\n",
    "\n",
    "task_config_path = lambda: f'./configs/tasks/molecule_net/{guacamol_task}/config.json'\n",
    "\n",
    "\n",
    "for guacamol_task in ['lipo']:\n",
    "    \n",
    "    task_config = TaskConfig.from_pretrained(task_config_path())\n",
    "    task_config.validate = False\n",
    "    task_config.split = 'test'\n",
    "    task_config.num_samples = 100\n",
    "    dataset = AutoDataset.from_config(task_config)\n",
    "    print(f\"Loaded {task_config.target_label} data.\")\n",
    "    \n",
    "    for model_name, path_to_model_config in PREDICTION_MODEL_CONFIGS.items():\n",
    "        \n",
    "        model_config = ModelConfig.from_pretrained(path_to_model_config)\n",
    "\n",
    "        trainer_config = TrainerConfig.from_pretrained('./configs/trainers/debug/')\n",
    "        logger_config = LoggerConfig.from_pretrained(DEFAULT_CONFIG_FILES['logger'])\n",
    "        \n",
    "        out_dir = f'./results/regression_task/guacamol/{model_name}/{guacamol_task}'\n",
    "        trainer_config.out_dir = out_dir\n",
    "        logger_config.name = model_name + '_' + guacamol_task\n",
    "        logger_config.project = 'debug'\n",
    "        trainer_config.enable_save_checkpoint = False\n",
    "        task_config.validate = False\n",
    "        logger_config.wandb_log = True\n",
    "        \n",
    "        dataset = AutoDataset.from_config(task_config)\n",
    "        tokenizer = AutoTokenizer.from_config(task_config)                \n",
    "        model = AutoModel.from_config(model_config)\n",
    "        logger = WandbLogger(logger_config, [task_config, model_config, trainer_config])\n",
    "        trainer = Trainer(config=trainer_config, model=model, train_dataset=dataset, eval_dataset=dataset, tokenizer=tokenizer, logger=logger)\n",
    "        \n",
    "        results = trainer.test(dataset)\n",
    "        \n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:13:10.369594384Z",
     "start_time": "2024-01-04T17:10:56.523302111Z"
    }
   },
   "id": "3f4cb44e009419ba"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "predictions = results[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:13:28.873726722Z",
     "start_time": "2024-01-04T17:13:28.841178046Z"
    }
   },
   "id": "452c8fe8bb7dd565"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "targets = results[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:13:29.099358718Z",
     "start_time": "2024-01-04T17:13:29.057803105Z"
    }
   },
   "id": "8416a831258c8dc"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3354])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(predictions).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:13:50.051440627Z",
     "start_time": "2024-01-04T17:13:50.018948570Z"
    }
   },
   "id": "dd182dbccf01494e"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3354])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(targets).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:13:57.427692585Z",
     "start_time": "2024-01-04T17:13:57.395423665Z"
    }
   },
   "id": "14364f19fa3d98a5"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "dataset.target_transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:22:17.492183543Z",
     "start_time": "2024-01-04T17:22:17.462824898Z"
    }
   },
   "id": "593987cd166c9cb0"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "dataset.target_transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:23:19.102557707Z",
     "start_time": "2024-01-04T17:23:19.070093994Z"
    }
   },
   "id": "a3d24b4c8b27946"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "from deepchem.feat.molecule_featurizers.raw_featurizer import RawFeaturizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:05.747285375Z",
     "start_time": "2024-01-04T17:25:05.703962864Z"
    }
   },
   "id": "74dffa001accfd7a"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "featurizer = RawFeaturizer(smiles=True)\n",
    "splitter = 'random'\n",
    "target_transforms = None\n",
    "a, b, c = dc.molnet.load_lipo(featurizer=featurizer, splitter=splitter)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:19.193980728Z",
     "start_time": "2024-01-04T17:25:19.159187096Z"
    }
   },
   "id": "a500b312228c7eb9"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c is not None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:25:28.482695689Z",
     "start_time": "2024-01-04T17:25:28.449894547Z"
    }
   },
   "id": "a3e80a7a897a9b2b"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "target_transforms = c if c is not None else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:26:14.043338859Z",
     "start_time": "2024-01-04T17:26:14.001073012Z"
    }
   },
   "id": "d633c5256398a48"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "[<deepchem.trans.transformers.NormalizationTransformer at 0x7f8e91352750>]"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_transforms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T17:26:16.344486625Z",
     "start_time": "2024-01-04T17:26:16.315351990Z"
    }
   },
   "id": "2c953f163a7be495"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.6860)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.Tensor([0.571, 0.914, 0.573]).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:14:44.109514766Z",
     "start_time": "2024-01-05T10:14:44.099372529Z"
    }
   },
   "id": "fe90305e9a8df97f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from hybrid_transformer.utils.datasets.utils import load_txt_into_list\n",
    "\n",
    "data = load_txt_into_list('../data/guacamol/train/smiles.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T13:16:10.250596938Z",
     "start_time": "2024-01-05T13:16:10.099608902Z"
    }
   },
   "id": "edc4a1c3496a1149"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "1273104"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T13:16:14.661290004Z",
     "start_time": "2024-01-05T13:16:14.653849987Z"
    }
   },
   "id": "a6385e3be5ac3338"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "431e0a5b9d71e590"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
