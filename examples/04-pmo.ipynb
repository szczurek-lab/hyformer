{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PMO experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os, logging, argparse, sys\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "from torch.distributed.elastic.multiprocessing.errors import record\n",
    "\n",
    "from hyformer.configs.dataset import DatasetConfig\n",
    "from hyformer.configs.tokenizer import TokenizerConfig\n",
    "from hyformer.configs.model import ModelConfig\n",
    "from hyformer.configs.trainer import TrainerConfig\n",
    "\n",
    "\n",
    "from hyformer.utils.datasets.auto import AutoDataset\n",
    "from hyformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from hyformer.models.auto import AutoModel\n",
    "\n",
    "\n",
    "from hyformer.trainers.trainer import Trainer\n",
    "\n",
    "\n",
    "from hyformer.utils.reproducibility import set_seed\n",
    "\n",
    "from experiments.pmo.utils import PMOOracle\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed and device\n",
    "\n",
    "set_seed(0)\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model \n",
    "\n",
    "TOKENIZER_CONFIG_PATH = \"configs/tokenizers/smiles/config.json\"\n",
    "MODEL_CONFIG_PATH = \"configs/models/hyformer_small/config.json\"\n",
    "TRAINER_CONFIG_PATH = \"configs/trainers/pmo/config.json\"\n",
    "\n",
    "MODEL_CKPT_PATH = \"/lustre/groups/aih/hyformer/results/distribution_learning/guacamol/hyformer_small/lm_enumerated/checkpoint.pt\"\n",
    "\n",
    "OUT_DIR = \"/lustre/groups/aih/hyformer/results/pmo/guacamol/{oracle_name}/hyformer_small/pmo\"\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "NUM_RETRAIN_EPOCHS = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyformer(\n",
       "  (token_embedding): Embedding(511, 256)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerLayer(\n",
       "      (attention_layer): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (relative_embedding): RotaryEmbedding()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (w3): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (w2): Linear(in_features=1024, out_features=256, bias=False)\n",
       "      )\n",
       "      (attention_layer_normalization): RMSNorm()\n",
       "      (feed_forward_normalization): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): RMSNorm()\n",
       "  (lm_head): Linear(in_features=256, out_features=511, bias=False)\n",
       "  (mlm_head): Linear(in_features=256, out_features=511, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load configurations\n",
    "\n",
    "tokenizer_config = TokenizerConfig.from_config_filepath(TOKENIZER_CONFIG_PATH)\n",
    "model_config = ModelConfig.from_config_filepath(MODEL_CONFIG_PATH)\n",
    "trainer_config = TrainerConfig.from_config_filepath(TRAINER_CONFIG_PATH)\n",
    "\n",
    "# Modify trainer config\n",
    "trainer_config.max_epochs = NUM_RETRAIN_EPOCHS\n",
    "\n",
    "# Initialize\n",
    "tokenizer = AutoTokenizer.from_config(tokenizer_config)\n",
    "model = AutoModel.from_config(model_config)\n",
    "model.load_pretrained(MODEL_CKPT_PATH)\n",
    "model.to(device)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    config=trainer_config,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORACLE_NAME = 'zaleplon_mpo'\n",
    "\n",
    "ORACLE_BUDGET = 10000\n",
    "NUM_ITERATIONS = 100\n",
    "FREQ_LOG = 100\n",
    "assert NUM_ITERATIONS * FREQ_LOG == ORACLE_BUDGET\n",
    "SEED = 0\n",
    "TEMPERATURE = 1.0  # scheduling temperature // start with 1.0 and anneal to 1.5 and then down to 0.9\n",
    "TOP_K = 10\n",
    "TOP_P = 0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GuacaMol benchmark: zaleplon_mpo\n",
      "Benchmark type: <class 'guacamol.goal_directed_benchmark.GoalDirectedBenchmark'>\n",
      "Oracle type: <class 'guacamol.scoring_function.GeometricMeanScoringFunction'>\n"
     ]
    }
   ],
   "source": [
    "oracle = PMOOracle(\n",
    "    name=ORACLE_NAME,\n",
    "    max_number_of_calls=ORACLE_BUDGET,\n",
    "    freq_log=FREQ_LOG,\n",
    "    dtype='none'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHAT ARE SATURN TRICKS?\n",
    "\n",
    "# get_data(data_transform=..., replay_buffer=...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to_generator(tokenizer=tokenizer, batch_size=1024, device=device, temperature=2.0, top_k=10, max_sequence_length=100, top_p=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples: 100%|██████████| 1/1 [00:20<00:00, 20.80s/it]\n"
     ]
    }
   ],
   "source": [
    "samples = model.generate(number_samples=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = oracle(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_top1': -1.0,\n",
       " 'avg_top10': -1.0,\n",
       " 'avg_top100': -1.0,\n",
       " 'auc_top1': nan,\n",
       " 'auc_top10': nan,\n",
       " 'auc_top100': nan,\n",
       " 'n_oracle': 540}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = \"Cc1ccc(cc1)C(C)C(C)C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.oracle.score([smiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyformer.utils.chemistry import is_valid\n",
    "\n",
    "is_valid(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracle.oracle.score(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Get Guacamol objectives.\n",
    "\n",
    "Source: https://github.com/BenevolentAI/guacamol/blob/master/guacamol/standard_benchmarks.py\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import Crippen, rdmolops\n",
    "from rdkit.Chem.QED import qed\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from guacamol import standard_benchmarks\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "med1 = standard_benchmarks.median_camphor_menthol()  # 'Median molecules 1'\n",
    "med2 = standard_benchmarks.median_tadalafil_sildenafil()  # 'Median molecules 2',\n",
    "pdop = standard_benchmarks.perindopril_rings()  # 'Perindopril MPO',\n",
    "osmb = standard_benchmarks.hard_osimertinib()  # 'Osimertinib MPO',\n",
    "adip = standard_benchmarks.amlodipine_rings()  # 'Amlodipine MPO'\n",
    "siga = standard_benchmarks.sitagliptin_replacement()  # 'Sitagliptin MPO'\n",
    "zale = standard_benchmarks.zaleplon_with_other_formula()  # 'Zaleplon MPO'\n",
    "valt = standard_benchmarks.valsartan_smarts()  # 'Valsartan SMARTS',\n",
    "dhop = standard_benchmarks.decoration_hop()  # 'Deco Hop'\n",
    "shop = standard_benchmarks.scaffold_hop()  # Scaffold Hop'\n",
    "rano= standard_benchmarks.ranolazine_mpo()  # 'Ranolazine MPO'\n",
    "fexo = standard_benchmarks.hard_fexofenadine()  # 'Fexofenadine MPO'... 'make fexofenadine less greasy'\n",
    "\n",
    "\n",
    "guacamol_objs = {\"med1\": med1, \"pdop\": pdop, \"adip\": adip, \"rano\": rano, \"osmb\": osmb, \"siga\": siga, \"zale\": zale,\n",
    "                 \"valt\": valt, \"med2\": med2, \"dhop\": dhop, \"shop\": shop, 'fexo': fexo}\n",
    "\n",
    "\n",
    "GUACAMOL_TASK_NAMES = [\n",
    "    'med1', 'pdop', 'adip', 'rano', 'osmb', 'siga',\n",
    "    'zale', 'valt', 'med2', 'dhop', 'shop', 'fexo',\n",
    "    'qed', 'qed_classification'\n",
    "]\n",
    "\n",
    "\n",
    "def smile_is_valid_mol(smile):\n",
    "    if smile is None or len(smile)==0:\n",
    "        return False\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol is None:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def smile_to_guacamole_score(obj_func_key, smile):\n",
    "    if smile is None or len(smile)==0:\n",
    "        return None\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    func = guacamol_objs[obj_func_key]\n",
    "    score = func.objective.score(smile)\n",
    "    if score is None:\n",
    "        return None\n",
    "    if score < 0:\n",
    "        return None\n",
    "    return score\n",
    "\n",
    "\n",
    "def smile_to_rdkit_mol(smile):\n",
    "    return Chem.MolFromSmiles(smile)\n",
    "\n",
    "\n",
    "def smile_to_QED(smile):\n",
    "    \"\"\"\n",
    "    Computes RDKit's QED score\n",
    "    \"\"\"\n",
    "    if smile is None:\n",
    "        return None\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    qed_score = qed(mol)\n",
    "    return qed_score\n",
    "\n",
    "\n",
    "def smile_to_sa(smile):\n",
    "    \"\"\"Synthetic Accessibility Score (SA):\n",
    "    a heuristic estimate of how hard (10)\n",
    "    or how easy (1) it is to synthesize a given molecule.\"\"\"\n",
    "    if smile is None:\n",
    "        return None\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return sascorer.calculateScore(mol)\n",
    "\n",
    "\n",
    "def smile_to_penalized_logP(smile):\n",
    "    \"\"\" calculate penalized logP for a given smiles string \"\"\"\n",
    "    if smile is None:\n",
    "        return None\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    logp = Crippen.MolLogP(mol)\n",
    "    sa = sascorer.calculateScore(mol)\n",
    "    cycle_length = _cycle_score(mol)\n",
    "    \"\"\"\n",
    "    Calculate final adjusted score.\n",
    "    These magic numbers are the empirical means and\n",
    "    std devs of the dataset.\n",
    "\n",
    "    I agree this is a weird way to calculate a score...\n",
    "    but this is what previous papers did!\n",
    "    \"\"\"\n",
    "    score = (\n",
    "            (logp - 2.45777691) / 1.43341767\n",
    "            + (-sa + 3.05352042) / 0.83460587\n",
    "            + (-cycle_length - -0.04861121) / 0.28746695\n",
    "    )\n",
    "    return max(score, -float(\"inf\"))\n",
    "\n",
    "\n",
    "def _cycle_score(mol):\n",
    "    cycle_list = nx.cycle_basis(nx.Graph(rdmolops.GetAdjacencyMatrix(mol)))\n",
    "    if len(cycle_list) == 0:\n",
    "        cycle_length = 0\n",
    "    else:\n",
    "        cycle_length = max([len(j) for j in cycle_list])\n",
    "    if cycle_length <= 6:\n",
    "        cycle_length = 0\n",
    "    else:\n",
    "        cycle_length = cycle_length - 6\n",
    "    return cycle_length\n",
    "\n",
    "\n",
    "def smiles_to_desired_scores(smiles_list, task_id=\"logp\", verbose=False):\n",
    "    if verbose:\n",
    "        return smiles_to_desired_scores_with_verbose(smiles_list, task_id)\n",
    "    else:\n",
    "        return smiles_to_desired_scores_without_verbose(smiles_list, task_id)\n",
    "\n",
    "\n",
    "def smiles_to_desired_scores_with_verbose(smiles_list, task_id=\"logp\"):\n",
    "    scores = []\n",
    "    for smiles_str in tqdm(smiles_list):\n",
    "        if task_id == \"logp\":\n",
    "            score_ = smile_to_penalized_logP(smiles_str)\n",
    "        elif task_id == \"qed\":\n",
    "            score_ = smile_to_QED(smiles_str)\n",
    "        else:  # otherwise, assume it is a guacamol task\n",
    "            score_ = smile_to_guacamole_score(task_id, smiles_str)\n",
    "        if (score_ is not None) and (math.isfinite(score_)):\n",
    "            scores.append(score_)\n",
    "        else:\n",
    "            scores.append(np.nan)\n",
    "\n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "def smiles_to_desired_scores_without_verbose(smiles_list, task_id=\"logp\"):\n",
    "    scores = []\n",
    "    for smiles_str in tqdm(smiles_list):\n",
    "        if task_id == \"logp\":\n",
    "            score_ = smile_to_penalized_logP(smiles_str)\n",
    "        elif task_id == \"qed\":\n",
    "            score_ = smile_to_QED(smiles_str)\n",
    "        else:  # otherwise, assume it is a guacamol task\n",
    "            score_ = smile_to_guacamole_score(task_id, smiles_str)\n",
    "        if (score_ is not None) and (math.isfinite(score_)):\n",
    "            scores.append(score_)\n",
    "        else:\n",
    "            scores.append(np.nan)\n",
    "\n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "def get_fingerprint_similarity(smile1, smile2):\n",
    "    mol1 = Chem.MolFromSmiles(smile1)\n",
    "    mol2 = Chem.MolFromSmiles(smile2)\n",
    "    if (mol1 is None) or (mol2 is None):\n",
    "        print(\"one of the input smiles is not a valid molecule!\")\n",
    "        return None\n",
    "    fp1 = FingerprintMols.FingerprintMol(mol1)\n",
    "    fp2 = FingerprintMols.FingerprintMol(mol2)\n",
    "    fps = DataStructs.FingerprintSimilarity(fp1, fp2)\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = smile_to_guacamole_score(smile=smiles, obj_func_key='zale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = guacamol_objs[\"zale\"]\n",
    "score = func.objective.score(\"CCCccc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
