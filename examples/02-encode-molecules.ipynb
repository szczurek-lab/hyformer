{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from hyformer.configs.dataset import DatasetConfig\n",
    "from hyformer.configs.tokenizer import TokenizerConfig\n",
    "from hyformer.configs.model import ModelConfig\n",
    "\n",
    "from hyformer.utils.datasets.auto import AutoDataset\n",
    "from hyformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from hyformer.models.auto import AutoModel\n",
    "\n",
    "from hyformer.configs.trainer import TrainerConfig\n",
    "from hyformer.trainers.trainer import Trainer\n",
    "\n",
    "# auxiliary imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from hyformer.models.wrappers import HyformerEncoderWrapper\n",
    "\n",
    "# autoreload magic\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "MODEL_NAME = 'hyformer'\n",
    "TASK_NAME = 'combined'\n",
    "OUTPUT_DIR = f\"/lustre/groups/aih/hyformer/results/distribution_learning/guacamol/{MODEL_NAME}/{TASK_NAME}/hpo/lr_6e-4\"\n",
    "DATASET_DIR = \"/lustre/groups/aih/hyformer/data\"\n",
    "\n",
    "DATASET_CONFIG_PATH = 'configs/datasets/guacamol/config.json'\n",
    "TOKENIZER_CONFIG_PATH = 'configs/tokenizers/smiles/guacamol/config.json'\n",
    "MODEL_CONFIG_PATH = 'configs/models/guacamol_vocab/hyformer/config.json'\n",
    "MODEL_CHECKPOINT_PATH = f'{OUTPUT_DIR}/ckpt.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "\n",
    "dataset_config = DatasetConfig.from_config_filepath(DATASET_CONFIG_PATH)\n",
    "test_dataset = AutoDataset.from_config(dataset_config, split=\"test\", root=DATASET_DIR)\n",
    "\n",
    "tokenizer_config = TokenizerConfig.from_config_filepath(TOKENIZER_CONFIG_PATH)\n",
    "tokenizer = AutoTokenizer.from_config(tokenizer_config)\n",
    "\n",
    "# Load model\n",
    "model_config = ModelConfig.from_config_filepath(MODEL_CONFIG_PATH)\n",
    "model = AutoModel.from_config(model_config)\n",
    "model.load_pretrained(filepath=MODEL_CHECKPOINT_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 16\n",
    "\n",
    "encoder = model.to_encoder(tokenizer=tokenizer, batch_size=batch_size, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding samples: 100%|██████████| 1/1 [00:04<00:00,  4.92s/it]\n"
     ]
    }
   ],
   "source": [
    "smiles = ['C1CCCCC1', 'C1CCCC1']\n",
    "embeddings = encoder.encode(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23591805, -0.71528178, -1.16197789, ..., -2.22820139,\n",
       "         1.0620836 , -1.64014733],\n",
       "       [-1.24176145, -0.73540109, -1.1245482 , ..., -2.21864176,\n",
       "         0.95939815, -1.68918061]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
