{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from hyformer.configs.dataset import DatasetConfig\n",
    "from hyformer.utils.datasets.auto import AutoDataset\n",
    "\n",
    "import lmdb\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from hyformer.utils.file_io import load_lmdb_file, infer_string_dtype, load_npy_with_progress\n",
    "\n",
    "\n",
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guacamol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "ROOT_DIR = \"/lustre/groups/aih/hyformer/data/\"\n",
    "DATASET_CONFIG_PATH = \"configs/datasets/guacamol/config.json\"\n",
    "\n",
    "_TARGET_DTYPE = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from raw files\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    data_filepath = f\"/lustre/groups/aih/hyformer/data/guacamol/raw/guacamol_v1_{split}.smiles\"\n",
    "    target_filepath = f\"/lustre/groups/aih/hyformer/data/guacamol/raw/guacamol_v1_{split}_physchem.npy\"\n",
    "    \n",
    "    split = 'val' if split == 'valid' else split\n",
    "    output_filepath = f\"/lustre/groups/aih/hyformer/data/guacamol/{split}.npz\"\n",
    "\n",
    "    with open(data_filepath) as f:\n",
    "        data = f.readlines()\n",
    "        # strip newlines\n",
    "        data = [line.strip() for line in data]\n",
    "\n",
    "    data = np.array(data, dtype=infer_string_dtype(data))\n",
    "    if target_filepath is not None:\n",
    "        target = np.load(target_filepath)\n",
    "        target = np.array(target, dtype=_TARGET_DTYPE)\n",
    "    else:\n",
    "        target = None\n",
    "        \n",
    "    assert len(data) == len(target)\n",
    "    assert len(data) > 0\n",
    "    assert not np.isnan(target).any()    \n",
    "\n",
    "    np.savez(output_filepath, smiles=data, target=target, np_version=np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "dataset_config = DatasetConfig.from_config_filepath(DATASET_CONFIG_PATH)\n",
    "train_dataset = AutoDataset.from_config(dataset_config, split=\"train\", root=ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'CCC(C)(C)Br',\n",
       " 'target': array([9.87045884e-01, 1.06082519e-03, 1.19277462e-03, 1.50628632e-03,\n",
       "        4.26654005e-03, 1.18353195e-03, 1.48528535e-03, 2.26715533e-03,\n",
       "        4.35905484e-03, 5.37506230e-02, 1.84731849e-03, 3.60329403e-03,\n",
       "        1.25289964e-03, 1.16366637e-03, 5.29900124e-10, 9.12536867e-03,\n",
       "        1.68455735e-01, 2.08328211e-12, 2.09409118e-01, 1.25655051e-14,\n",
       "        6.40781581e-01, 6.72773922e-07, 6.62113089e-05, 8.39246273e-01,\n",
       "        1.54497937e-09, 3.67336208e-03, 9.76835668e-01, 2.46493757e-01,\n",
       "        2.00206954e-02, 9.88905191e-01, 9.98220146e-01, 1.21400598e-02,\n",
       "        3.83887859e-03, 1.55595524e-06, 1.99896260e-03, 1.87800045e-03,\n",
       "        6.13564610e-01, 1.46966905e-03, 1.20975282e-02, 3.48386802e-02,\n",
       "        1.20975282e-02, 9.79107898e-03, 8.92802358e-01, 2.81951297e-03,\n",
       "        8.25417519e-01, 9.62890148e-01, 2.81724334e-01, 2.08300631e-03,\n",
       "        3.78650404e-03, 1.08171754e-01, 3.56361419e-02, 1.57206312e-01,\n",
       "        1.54784873e-01, 6.61882162e-02, 3.35549749e-02, 1.07963331e-01,\n",
       "        1.15514416e-02, 2.04088036e-02, 1.95919156e-08, 2.83892360e-02,\n",
       "        5.30138095e-05, 3.18661928e-02, 4.21906177e-10, 6.21897629e-12,\n",
       "        4.66977759e-12, 1.92366855e-03, 5.34489229e-02, 2.43214799e-06,\n",
       "        7.36094941e-21, 9.97377992e-15, 6.15242753e-12, 2.99188467e-23,\n",
       "        1.33660242e-01, 8.18025246e-02, 6.39449987e-18, 1.03773039e-21,\n",
       "        6.94524348e-01, 4.67544757e-02, 1.10834174e-01, 8.25032450e-23,\n",
       "        2.97622085e-02, 2.21052561e-02, 3.81737918e-01, 1.66521236e-01,\n",
       "        2.81677242e-13, 8.58482290e-21, 5.92715502e-01, 2.45021619e-02,\n",
       "        1.97826512e-02, 5.30138095e-05, 5.37170646e-21, 6.43609749e-11,\n",
       "        4.84694374e-09, 8.12893397e-09, 9.76941109e-01, 6.80974778e-03,\n",
       "        1.14875252e-06, 2.52232724e-03, 5.47477126e-01, 2.54666395e-02,\n",
       "        1.58003077e-01, 1.46350347e-12, 5.30138095e-05, 5.96816419e-04,\n",
       "        5.30138095e-05, 7.37404227e-01, 5.30138095e-05, 5.30138095e-05,\n",
       "        5.30138095e-05, 5.30138095e-05, 5.30138095e-05, 5.30138095e-05,\n",
       "        7.60214686e-01, 6.49605354e-04, 7.68421090e-16, 1.44039669e-10,\n",
       "        4.48075720e-22, 2.05900144e-16, 7.44840008e-13, 4.37661934e-19,\n",
       "        4.22110829e-17, 1.65277869e-01, 3.91346176e-21, 6.10601565e-22,\n",
       "        5.56908324e-02, 1.78235399e-10, 1.68239057e-01, 1.68433398e-01,\n",
       "        1.67176872e-01, 2.39678826e-07, 5.35215975e-07, 9.10250111e-24,\n",
       "        7.10542736e-15, 4.04533473e-17, 8.84845522e-21, 4.22110829e-17,\n",
       "        1.68410555e-01, 7.10542736e-15, 1.68421701e-01, 9.99691367e-01,\n",
       "        1.66072756e-01, 2.40722575e-09, 4.37642723e-21, 2.18792107e-12,\n",
       "        1.24630228e-09, 3.84151406e-07, 3.53935334e-08, 3.28785158e-03,\n",
       "        3.36583667e-02, 1.75615102e-01, 1.30963906e-10, 5.30138095e-05,\n",
       "        3.30171257e-01, 3.24445264e-03, 1.14320693e-18, 1.56417817e-01,\n",
       "        9.31097865e-19, 9.87018691e-04, 8.76104295e-01, 1.68344572e-01,\n",
       "        1.67911395e-01, 3.03015516e-20, 1.67947829e-01, 5.30138095e-05,\n",
       "        4.64911973e-05, 5.58655710e-19, 1.66536629e-01, 2.36350391e-03,\n",
       "        1.68184564e-01, 1.55856013e-01, 4.78778601e-21, 2.48965936e-21,\n",
       "        2.74074136e-18, 4.31364834e-21, 1.68070138e-01, 3.28785158e-03,\n",
       "        1.28453237e-03, 1.11786969e-12, 1.56521276e-01, 1.66378975e-01,\n",
       "        5.01284521e-18, 7.10542736e-15, 5.14927256e-09, 3.06407788e-10,\n",
       "        2.99153402e-16, 1.67876571e-01, 5.30138095e-05, 1.56559557e-01,\n",
       "        7.10542736e-15, 1.66042581e-01, 5.84955231e-24, 7.45120599e-13,\n",
       "        7.10542736e-15, 1.68407351e-01, 1.67338476e-01, 2.46837968e-04,\n",
       "        3.47672713e-17, 1.64656892e-01, 2.83918006e-16, 3.98394734e-01],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_idx = 0\n",
    "train_dataset[_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoleculeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOLECULE_NET_DATASETS = [\n",
    "    \"bace\",\n",
    "    \"bbbp\",\n",
    "    \"clintox\",\n",
    "    \"esol\",\n",
    "    \"freesolv\",\n",
    "    \"hiv\",\n",
    "    \"lipo\",\n",
    "    \"sider\",\n",
    "    \"tox21\",\n",
    "    \"toxcast\"\n",
    "    ]\n",
    "\n",
    "SPLITS = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "\n",
    "ROOT_DIR = \"/lustre/groups/aih/hyformer/data/\"\n",
    "\n",
    "INPUT_FILE_PATH = \"molecule_net/raw/{dataset}/{split}.lmdb\"\n",
    "OUTPUT_FILE_PATH = \"molecule_net/scaffold/{dataset}/{split}.npz\"\n",
    "\n",
    "_TARGET_DTYPE = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import indices\n",
    "\n",
    "\n",
    "for dataset in MOLECULE_NET_DATASETS:\n",
    "    for split in SPLITS:\n",
    "        input_file_path = os.path.join(ROOT_DIR, INPUT_FILE_PATH.format(dataset=dataset, split=split))\n",
    "        output_file_path = os.path.join(ROOT_DIR, OUTPUT_FILE_PATH.format(dataset=dataset, split=split))\n",
    "        \n",
    "        env = lmdb.open(\n",
    "            input_file_path,\n",
    "            subdir=False,\n",
    "            readonly=True,\n",
    "            lock=False,\n",
    "            readahead=False,\n",
    "            meminit=False,\n",
    "            max_readers=256,\n",
    "        )\n",
    "        txn = env.begin()\n",
    "        keys = list(txn.cursor().iternext(values=False))\n",
    "        data = []\n",
    "        target = []\n",
    "        original_idx = []\n",
    "        for idx in keys:\n",
    "            datapoint_pickled = txn.get(idx)\n",
    "            datapoint = pickle.loads(datapoint_pickled)\n",
    "            data.append(datapoint['smi'])\n",
    "            target.append(datapoint['target'])\n",
    "            original_idx.append(datapoint['ori_index'])\n",
    "            \n",
    "        data = np.array(data, dtype=infer_string_dtype(data))\n",
    "        target = np.array(target, dtype=_TARGET_DTYPE)\n",
    "        if len(target.shape) == 1:\n",
    "            target = target.reshape(-1, 1)\n",
    "        original_idx = np.array(original_idx, dtype=np.int32)\n",
    "        \n",
    "        np.savez(output_file_path, smiles=data, target=target, np_version=np.__version__, original_idx=original_idx)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lo benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded kdr train 1 from /lustre/groups/aih/hyformer/data/lo/raw/kdr/train_1.csv\n",
      "Saved kdr train 1 to /lustre/groups/aih/hyformer/data/lo/kdr/train_1.npz\n",
      "Saved kdr val 1 to /lustre/groups/aih/hyformer/data/lo/kdr/val_1.npz\n",
      "Loaded kdr test 1 from /lustre/groups/aih/hyformer/data/lo/raw/kdr/test_1.csv\n",
      "Saved kdr test 1 to /lustre/groups/aih/hyformer/data/lo/kdr/test_1.npz\n",
      "Loaded kdr train 2 from /lustre/groups/aih/hyformer/data/lo/raw/kdr/train_2.csv\n",
      "Saved kdr train 2 to /lustre/groups/aih/hyformer/data/lo/kdr/train_2.npz\n",
      "Saved kdr val 2 to /lustre/groups/aih/hyformer/data/lo/kdr/val_2.npz\n",
      "Loaded kdr test 2 from /lustre/groups/aih/hyformer/data/lo/raw/kdr/test_2.csv\n",
      "Saved kdr test 2 to /lustre/groups/aih/hyformer/data/lo/kdr/test_2.npz\n",
      "Loaded kdr train 3 from /lustre/groups/aih/hyformer/data/lo/raw/kdr/train_3.csv\n",
      "Saved kdr train 3 to /lustre/groups/aih/hyformer/data/lo/kdr/train_3.npz\n",
      "Saved kdr val 3 to /lustre/groups/aih/hyformer/data/lo/kdr/val_3.npz\n",
      "Loaded kdr test 3 from /lustre/groups/aih/hyformer/data/lo/raw/kdr/test_3.csv\n",
      "Saved kdr test 3 to /lustre/groups/aih/hyformer/data/lo/kdr/test_3.npz\n",
      "Loaded kcnh2 train 1 from /lustre/groups/aih/hyformer/data/lo/raw/kcnh2/train_1.csv\n",
      "Saved kcnh2 train 1 to /lustre/groups/aih/hyformer/data/lo/kcnh2/train_1.npz\n",
      "Saved kcnh2 val 1 to /lustre/groups/aih/hyformer/data/lo/kcnh2/val_1.npz\n",
      "Loaded kcnh2 test 1 from /lustre/groups/aih/hyformer/data/lo/raw/kcnh2/test_1.csv\n",
      "Saved kcnh2 test 1 to /lustre/groups/aih/hyformer/data/lo/kcnh2/test_1.npz\n",
      "Loaded kcnh2 train 2 from /lustre/groups/aih/hyformer/data/lo/raw/kcnh2/train_2.csv\n",
      "Saved kcnh2 train 2 to /lustre/groups/aih/hyformer/data/lo/kcnh2/train_2.npz\n",
      "Saved kcnh2 val 2 to /lustre/groups/aih/hyformer/data/lo/kcnh2/val_2.npz\n",
      "Loaded kcnh2 test 2 from /lustre/groups/aih/hyformer/data/lo/raw/kcnh2/test_2.csv\n",
      "Saved kcnh2 test 2 to /lustre/groups/aih/hyformer/data/lo/kcnh2/test_2.npz\n",
      "Loaded kcnh2 train 3 from /lustre/groups/aih/hyformer/data/lo/raw/kcnh2/train_3.csv\n",
      "Saved kcnh2 train 3 to /lustre/groups/aih/hyformer/data/lo/kcnh2/train_3.npz\n",
      "Saved kcnh2 val 3 to /lustre/groups/aih/hyformer/data/lo/kcnh2/val_3.npz\n",
      "Loaded kcnh2 test 3 from /lustre/groups/aih/hyformer/data/lo/raw/kcnh2/test_3.csv\n",
      "Saved kcnh2 test 3 to /lustre/groups/aih/hyformer/data/lo/kcnh2/test_3.npz\n",
      "Loaded drd2 train 1 from /lustre/groups/aih/hyformer/data/lo/raw/drd2/train_1.csv\n",
      "Saved drd2 train 1 to /lustre/groups/aih/hyformer/data/lo/drd2/train_1.npz\n",
      "Saved drd2 val 1 to /lustre/groups/aih/hyformer/data/lo/drd2/val_1.npz\n",
      "Loaded drd2 test 1 from /lustre/groups/aih/hyformer/data/lo/raw/drd2/test_1.csv\n",
      "Saved drd2 test 1 to /lustre/groups/aih/hyformer/data/lo/drd2/test_1.npz\n",
      "Loaded drd2 train 2 from /lustre/groups/aih/hyformer/data/lo/raw/drd2/train_2.csv\n",
      "Saved drd2 train 2 to /lustre/groups/aih/hyformer/data/lo/drd2/train_2.npz\n",
      "Saved drd2 val 2 to /lustre/groups/aih/hyformer/data/lo/drd2/val_2.npz\n",
      "Loaded drd2 test 2 from /lustre/groups/aih/hyformer/data/lo/raw/drd2/test_2.csv\n",
      "Saved drd2 test 2 to /lustre/groups/aih/hyformer/data/lo/drd2/test_2.npz\n",
      "Loaded drd2 train 3 from /lustre/groups/aih/hyformer/data/lo/raw/drd2/train_3.csv\n",
      "Saved drd2 train 3 to /lustre/groups/aih/hyformer/data/lo/drd2/train_3.npz\n",
      "Saved drd2 val 3 to /lustre/groups/aih/hyformer/data/lo/drd2/val_3.npz\n",
      "Loaded drd2 test 3 from /lustre/groups/aih/hyformer/data/lo/raw/drd2/test_3.csv\n",
      "Saved drd2 test 3 to /lustre/groups/aih/hyformer/data/lo/drd2/test_3.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_DIR = \"/lustre/groups/aih/hyformer/data/lo/raw\"\n",
    "OUTPUT_DIR = \"/lustre/groups/aih/hyformer/data/lo\"\n",
    "DATASETS = ['kdr', 'kcnh2', 'drd2']\n",
    "SPLITS = ['train', 'test']\n",
    "SEEDS = [1, 2, 3]\n",
    "\n",
    "_TARGET_DTYPE = np.float32\n",
    "_CLUSTER_DTYPE = np.int32\n",
    "\n",
    "input_data_filepath = \"{split}_{seed}.csv\"\n",
    "output_data_filepath = \"{split}_{seed}.npz\"\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    \n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, dataset), exist_ok=True)\n",
    "    \n",
    "    for seed in SEEDS:\n",
    "\n",
    "        for split in SPLITS:        \n",
    "            \n",
    "            input_file_path = os.path.join(DATA_DIR, dataset, input_data_filepath.format(dataset=dataset, split=split, seed=seed))  \n",
    "            df = pd.read_csv(input_file_path, index_col=0)\n",
    "            print(f\"Loaded {dataset} {split} {seed} from {input_file_path}\")\n",
    "            \n",
    "            if split == 'train':\n",
    "                df_train, df_valid = train_test_split(df, test_size=0.1, random_state=seed)\n",
    "            \n",
    "                smiles = df_train['smiles'].to_numpy()\n",
    "                target = df_train['value'].to_numpy()\n",
    "                cluster = df_train['cluster'].to_numpy()\n",
    "                \n",
    "                smiles = np.array(smiles, dtype=infer_string_dtype(smiles))\n",
    "                target = np.array(target, dtype=_TARGET_DTYPE)\n",
    "                cluster = np.array(cluster, dtype=_CLUSTER_DTYPE)\n",
    "\n",
    "                target = target.reshape(-1, 1) if len(target.shape) == 1 else target\n",
    "                \n",
    "                _output_file_path = os.path.join(OUTPUT_DIR, dataset, output_data_filepath.format(dataset=dataset, split=split, seed=seed))\n",
    "                np.savez(_output_file_path, smiles=smiles, target=target, cluster=cluster, np_version=np.__version__)\n",
    "                \n",
    "                print(f\"Saved {dataset} {split} {seed} to {_output_file_path}\")\n",
    "                split = 'val'\n",
    "                \n",
    "                smiles = df_valid['smiles'].to_numpy()\n",
    "                target = df_valid['value'].to_numpy()\n",
    "                cluster = df_valid['cluster'].to_numpy()\n",
    "                \n",
    "                smiles = np.array(smiles, dtype=infer_string_dtype(smiles))\n",
    "                target = np.array(target, dtype=_TARGET_DTYPE)\n",
    "                cluster = np.array(cluster, dtype=_CLUSTER_DTYPE)\n",
    "\n",
    "                target = target.reshape(-1, 1) if len(target.shape) == 1 else target\n",
    "                \n",
    "                _output_file_path = os.path.join(OUTPUT_DIR, dataset, output_data_filepath.format(dataset=dataset, split=split, seed=seed))\n",
    "                np.savez(_output_file_path, smiles=smiles, target=target, cluster=cluster, np_version=np.__version__)\n",
    "\n",
    "                print(f\"Saved {dataset} {split} {seed} to {_output_file_path}\")\n",
    "                \n",
    "            else:\n",
    "                smiles = df['smiles'].to_numpy()\n",
    "                target = df['value'].to_numpy()\n",
    "                cluster = df['cluster'].to_numpy()\n",
    "                \n",
    "                smiles = np.array(smiles, dtype=infer_string_dtype(smiles))\n",
    "                target = np.array(target, dtype=_TARGET_DTYPE)\n",
    "                cluster = np.array(cluster, dtype=_CLUSTER_DTYPE)\n",
    "\n",
    "                target = target.reshape(-1, 1) if len(target.shape) == 1 else target\n",
    "                \n",
    "                _output_file_path = os.path.join(OUTPUT_DIR, dataset, output_data_filepath.format(dataset=dataset, split=split, seed=seed))\n",
    "                np.savez(_output_file_path, smiles=smiles, target=target, cluster=cluster, np_version=np.__version__)\n",
    "                \n",
    "                print(f\"Saved {dataset} {split} {seed} to {_output_file_path}\")\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded kdr train 1 from /lustre/groups/aih/hyformer/data/hi/raw/kdr/train_1.csv\n",
      "Saved kdr train 1 to /lustre/groups/aih/hyformer/data/hi/kdr/train_1.npz\n",
      "Saved kdr val 1 to /lustre/groups/aih/hyformer/data/hi/kdr/val_1.npz\n",
      "Loaded kdr test 1 from /lustre/groups/aih/hyformer/data/hi/raw/kdr/test_1.csv\n",
      "Saved kdr test 1 to /lustre/groups/aih/hyformer/data/hi/kdr/test_1.npz\n",
      "Loaded kdr train 2 from /lustre/groups/aih/hyformer/data/hi/raw/kdr/train_2.csv\n",
      "Saved kdr train 2 to /lustre/groups/aih/hyformer/data/hi/kdr/train_2.npz\n",
      "Saved kdr val 2 to /lustre/groups/aih/hyformer/data/hi/kdr/val_2.npz\n",
      "Loaded kdr test 2 from /lustre/groups/aih/hyformer/data/hi/raw/kdr/test_2.csv\n",
      "Saved kdr test 2 to /lustre/groups/aih/hyformer/data/hi/kdr/test_2.npz\n",
      "Loaded kdr train 3 from /lustre/groups/aih/hyformer/data/hi/raw/kdr/train_3.csv\n",
      "Saved kdr train 3 to /lustre/groups/aih/hyformer/data/hi/kdr/train_3.npz\n",
      "Saved kdr val 3 to /lustre/groups/aih/hyformer/data/hi/kdr/val_3.npz\n",
      "Loaded kdr test 3 from /lustre/groups/aih/hyformer/data/hi/raw/kdr/test_3.csv\n",
      "Saved kdr test 3 to /lustre/groups/aih/hyformer/data/hi/kdr/test_3.npz\n",
      "Loaded hiv train 1 from /lustre/groups/aih/hyformer/data/hi/raw/hiv/train_1.csv\n",
      "Saved hiv train 1 to /lustre/groups/aih/hyformer/data/hi/hiv/train_1.npz\n",
      "Saved hiv val 1 to /lustre/groups/aih/hyformer/data/hi/hiv/val_1.npz\n",
      "Loaded hiv test 1 from /lustre/groups/aih/hyformer/data/hi/raw/hiv/test_1.csv\n",
      "Saved hiv test 1 to /lustre/groups/aih/hyformer/data/hi/hiv/test_1.npz\n",
      "Loaded hiv train 2 from /lustre/groups/aih/hyformer/data/hi/raw/hiv/train_2.csv\n",
      "Saved hiv train 2 to /lustre/groups/aih/hyformer/data/hi/hiv/train_2.npz\n",
      "Saved hiv val 2 to /lustre/groups/aih/hyformer/data/hi/hiv/val_2.npz\n",
      "Loaded hiv test 2 from /lustre/groups/aih/hyformer/data/hi/raw/hiv/test_2.csv\n",
      "Saved hiv test 2 to /lustre/groups/aih/hyformer/data/hi/hiv/test_2.npz\n",
      "Loaded hiv train 3 from /lustre/groups/aih/hyformer/data/hi/raw/hiv/train_3.csv\n",
      "Saved hiv train 3 to /lustre/groups/aih/hyformer/data/hi/hiv/train_3.npz\n",
      "Saved hiv val 3 to /lustre/groups/aih/hyformer/data/hi/hiv/val_3.npz\n",
      "Loaded hiv test 3 from /lustre/groups/aih/hyformer/data/hi/raw/hiv/test_3.csv\n",
      "Saved hiv test 3 to /lustre/groups/aih/hyformer/data/hi/hiv/test_3.npz\n",
      "Loaded drd2 train 1 from /lustre/groups/aih/hyformer/data/hi/raw/drd2/train_1.csv\n",
      "Saved drd2 train 1 to /lustre/groups/aih/hyformer/data/hi/drd2/train_1.npz\n",
      "Saved drd2 val 1 to /lustre/groups/aih/hyformer/data/hi/drd2/val_1.npz\n",
      "Loaded drd2 test 1 from /lustre/groups/aih/hyformer/data/hi/raw/drd2/test_1.csv\n",
      "Saved drd2 test 1 to /lustre/groups/aih/hyformer/data/hi/drd2/test_1.npz\n",
      "Loaded drd2 train 2 from /lustre/groups/aih/hyformer/data/hi/raw/drd2/train_2.csv\n",
      "Saved drd2 train 2 to /lustre/groups/aih/hyformer/data/hi/drd2/train_2.npz\n",
      "Saved drd2 val 2 to /lustre/groups/aih/hyformer/data/hi/drd2/val_2.npz\n",
      "Loaded drd2 test 2 from /lustre/groups/aih/hyformer/data/hi/raw/drd2/test_2.csv\n",
      "Saved drd2 test 2 to /lustre/groups/aih/hyformer/data/hi/drd2/test_2.npz\n",
      "Loaded drd2 train 3 from /lustre/groups/aih/hyformer/data/hi/raw/drd2/train_3.csv\n",
      "Saved drd2 train 3 to /lustre/groups/aih/hyformer/data/hi/drd2/train_3.npz\n",
      "Saved drd2 val 3 to /lustre/groups/aih/hyformer/data/hi/drd2/val_3.npz\n",
      "Loaded drd2 test 3 from /lustre/groups/aih/hyformer/data/hi/raw/drd2/test_3.csv\n",
      "Saved drd2 test 3 to /lustre/groups/aih/hyformer/data/hi/drd2/test_3.npz\n",
      "Loaded sol train 1 from /lustre/groups/aih/hyformer/data/hi/raw/sol/train_1.csv\n",
      "Saved sol train 1 to /lustre/groups/aih/hyformer/data/hi/sol/train_1.npz\n",
      "Saved sol val 1 to /lustre/groups/aih/hyformer/data/hi/sol/val_1.npz\n",
      "Loaded sol test 1 from /lustre/groups/aih/hyformer/data/hi/raw/sol/test_1.csv\n",
      "Saved sol test 1 to /lustre/groups/aih/hyformer/data/hi/sol/test_1.npz\n",
      "Loaded sol train 2 from /lustre/groups/aih/hyformer/data/hi/raw/sol/train_2.csv\n",
      "Saved sol train 2 to /lustre/groups/aih/hyformer/data/hi/sol/train_2.npz\n",
      "Saved sol val 2 to /lustre/groups/aih/hyformer/data/hi/sol/val_2.npz\n",
      "Loaded sol test 2 from /lustre/groups/aih/hyformer/data/hi/raw/sol/test_2.csv\n",
      "Saved sol test 2 to /lustre/groups/aih/hyformer/data/hi/sol/test_2.npz\n",
      "Loaded sol train 3 from /lustre/groups/aih/hyformer/data/hi/raw/sol/train_3.csv\n",
      "Saved sol train 3 to /lustre/groups/aih/hyformer/data/hi/sol/train_3.npz\n",
      "Saved sol val 3 to /lustre/groups/aih/hyformer/data/hi/sol/val_3.npz\n",
      "Loaded sol test 3 from /lustre/groups/aih/hyformer/data/hi/raw/sol/test_3.csv\n",
      "Saved sol test 3 to /lustre/groups/aih/hyformer/data/hi/sol/test_3.npz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sympy import O\n",
    "\n",
    "\n",
    "DATA_DIR = \"/lustre/groups/aih/hyformer/data/hi/raw\"\n",
    "OUTPUT_DIR = \"/lustre/groups/aih/hyformer/data/hi\"\n",
    "DATASETS = ['kdr', 'hiv', 'drd2', 'sol']\n",
    "SPLITS = ['train', 'test']\n",
    "SEEDS = [1, 2, 3]\n",
    "\n",
    "_TARGET_DTYPE = np.float32\n",
    "\n",
    "input_data_filepath = \"{split}_{seed}.csv\"\n",
    "output_data_filepath = \"{split}_{seed}.npz\"\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    \n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, dataset), exist_ok=True)\n",
    "    \n",
    "    for seed in SEEDS:\n",
    "\n",
    "        for split in SPLITS:        \n",
    "            \n",
    "            input_file_path = os.path.join(DATA_DIR, dataset, input_data_filepath.format(dataset=dataset, split=split, seed=seed))  \n",
    "            df = pd.read_csv(input_file_path, index_col=0)\n",
    "            print(f\"Loaded {dataset} {split} {seed} from {input_file_path}\")\n",
    "            \n",
    "            if split == 'train':\n",
    "                df_train, df_valid = train_test_split(df, test_size=0.1, random_state=seed)\n",
    "            \n",
    "                smiles = df_train['smiles'].to_numpy()\n",
    "                target = df_train['value'].to_numpy()\n",
    "                \n",
    "                smiles = np.array(smiles, dtype=infer_string_dtype(smiles))\n",
    "                target = np.array(target, dtype=_TARGET_DTYPE)\n",
    "\n",
    "                target = target.reshape(-1, 1) if len(target.shape) == 1 else target\n",
    "                \n",
    "                _output_file_path = os.path.join(OUTPUT_DIR, dataset, output_data_filepath.format(dataset=dataset, split=split, seed=seed))\n",
    "                np.savez(_output_file_path, smiles=smiles, target=target, np_version=np.__version__)\n",
    "                \n",
    "                print(f\"Saved {dataset} {split} {seed} to {_output_file_path}\")\n",
    "                split = 'val'\n",
    "                \n",
    "                smiles = df_valid['smiles'].to_numpy()\n",
    "                target = df_valid['value'].to_numpy()\n",
    "                \n",
    "                smiles = np.array(smiles, dtype=infer_string_dtype(smiles))\n",
    "                target = np.array(target, dtype=_TARGET_DTYPE)\n",
    "\n",
    "                target = target.reshape(-1, 1) if len(target.shape) == 1 else target\n",
    "                \n",
    "                _output_file_path = os.path.join(OUTPUT_DIR, dataset, output_data_filepath.format(dataset=dataset, split=split, seed=seed))\n",
    "                np.savez(_output_file_path, smiles=smiles, target=target, np_version=np.__version__)\n",
    "\n",
    "                print(f\"Saved {dataset} {split} {seed} to {_output_file_path}\")\n",
    "                \n",
    "            else:\n",
    "                smiles = df['smiles'].to_numpy()\n",
    "                target = df['value'].to_numpy()\n",
    "                \n",
    "                smiles = np.array(smiles, dtype=infer_string_dtype(smiles))\n",
    "                target = np.array(target, dtype=_TARGET_DTYPE)\n",
    "\n",
    "                target = target.reshape(-1, 1) if len(target.shape) == 1 else target\n",
    "                \n",
    "                _output_file_path = os.path.join(OUTPUT_DIR, dataset, output_data_filepath.format(dataset=dataset, split=split, seed=seed))\n",
    "                np.savez(_output_file_path, smiles=smiles, target=target, np_version=np.__version__)\n",
    "                \n",
    "                print(f\"Saved {dataset} {split} {seed} to {_output_file_path}\")\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
