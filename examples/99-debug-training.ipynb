{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os, logging, argparse, sys\n",
    "\n",
    "import torch\n",
    "\n",
    "from hyformer.configs.dataset import DatasetConfig\n",
    "from hyformer.configs.tokenizer import TokenizerConfig\n",
    "from hyformer.configs.model import ModelConfig\n",
    "from hyformer.configs.trainer import TrainerConfig\n",
    "\n",
    "\n",
    "from hyformer.utils.datasets.auto import AutoDataset\n",
    "from hyformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from hyformer.models.auto import AutoModel\n",
    "\n",
    "\n",
    "from hyformer.trainers.trainer import Trainer\n",
    "\n",
    "from hyformer.utils.reproducibility import set_seed\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/lustre/groups/aih/hyformer/data\"\n",
    "\n",
    "DATASET_CONFIG_PATH = \"configs/datasets/guacamol/config.json\"\n",
    "TOKENIZER_CONFIG_PATH = \"configs/tokenizers/smiles/guacamol/config.json\"\n",
    "MODEL_CONFIG_PATH = \"configs/models/hyformer_small/config.json\"\n",
    "TRAINER_CONFIG_PATH = \"configs/trainers/distribution_learning/guacamol/lm/config.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "dataset_config = DatasetConfig.from_config_filepath(DATASET_CONFIG_PATH)\n",
    "tokenizer_config = TokenizerConfig.from_config_filepath(TOKENIZER_CONFIG_PATH)\n",
    "model_config = ModelConfig.from_config_filepath(MODEL_CONFIG_PATH)\n",
    "trainer_config = TrainerConfig.from_config_filepath(TRAINER_CONFIG_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "train_dataset = AutoDataset.from_config(dataset_config, split='train', root=DATA_DIR)\n",
    "val_dataset = AutoDataset.from_config(dataset_config, split='val', root=DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_config(tokenizer_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = AutoModel.from_config(model_config)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the device\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    config=trainer_config,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [train_dataset[i]['data'] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCC(C)(C)Br', 'CCCN(CCc1cccc(-c2ccccc2)c1)C(=O)C1OC(C(=O)O)=CC(N)C1NC(C)=O']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[102, 19, 19, 19, 4, 19, 5, 4, 19, 5, 18, 103],\n",
       "  [102,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   23,\n",
       "   4,\n",
       "   19,\n",
       "   19,\n",
       "   97,\n",
       "   7,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   4,\n",
       "   6,\n",
       "   97,\n",
       "   8,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   8,\n",
       "   5,\n",
       "   97,\n",
       "   7,\n",
       "   5,\n",
       "   19,\n",
       "   4,\n",
       "   16,\n",
       "   24,\n",
       "   5,\n",
       "   19,\n",
       "   7,\n",
       "   24,\n",
       "   19,\n",
       "   4,\n",
       "   19,\n",
       "   4,\n",
       "   16,\n",
       "   24,\n",
       "   5,\n",
       "   24,\n",
       "   5,\n",
       "   16,\n",
       "   19,\n",
       "   19,\n",
       "   4,\n",
       "   23,\n",
       "   5,\n",
       "   19,\n",
       "   7,\n",
       "   23,\n",
       "   19,\n",
       "   4,\n",
       "   19,\n",
       "   5,\n",
       "   16,\n",
       "   24,\n",
       "   103]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(samples, task='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCC(C)(C)Br'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(torch.tensor(tokenizer(samples, task='lm')['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/groups/aih/hyformer/env/hyformer_experiments/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "trainer_loader = trainer.create_loader(train_dataset, shuffle=True, tasks=trainer.config.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/groups/aih/hyformer/env/hyformer_experiments/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(trainer_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O=C(O)C1C2CC=CC2c2cc(Cl)cc3c2N1CC1CC=CC31'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(batch['input_ids'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([508, 503,  29,  21,  24,   6,  29,   7,  24,  12,  24,  13,  24,  24,\n",
       "         21,  24,  24,  13, 498,  13, 498, 498,   6,  25,   7, 498, 498,  14,\n",
       "        498,  13,  28,  12,  24,  24,  12,  24,  24,  21,  24,  24,  14,  12,\n",
       "        504, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505,\n",
       "        505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505,\n",
       "        505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505,\n",
       "        505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505,\n",
       "        505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505,\n",
       "        505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505, 505,\n",
       "        505, 505])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100,   29,   21,   24,    6,   29,    7,   24,   12,   24,   13,\n",
       "          24,   24,   21,   24,   24,   13,  498,   13,  498,  498,    6,   25,\n",
       "           7,  498,  498,   14,  498,   13,   28,   12,   24,   24,   12,   24,\n",
       "          24,   21,   24,   24,   14,   12,  504, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_labels'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attention_mask'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "from hyformer.models.layers.rotary import RotaryEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from hyformer.models.layers.rotary import RotaryEmbedding\n",
    "\n",
    "# instantiate the positional embedding in your transformer and pass to all your attention layers\n",
    "\n",
    "rotary_emb = RotaryEmbedding(dim = 32)\n",
    "\n",
    "# mock queries and keys - dimensions should end with (seq_len, feature dimension), and any number of preceding dimensions (batch, heads, etc)\n",
    "\n",
    "q = torch.randn(1, 2, 8, 64) # queries - (batch, heads, seq len, dimension of head)\n",
    "k = torch.randn(1, 2, 8, 64) # keys\n",
    "\n",
    "# apply the rotations to your queries and keys after the heads have been split out, but prior to the dot product and subsequent softmax (attention)\n",
    "\n",
    "q = rotary_emb.rotate_queries_or_keys(q)\n",
    "k = rotary_emb.rotate_queries_or_keys(k)\n",
    "\n",
    "# then do your attention with your queries (q) and keys (k) as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_idx = 2\n",
    "q = torch.randn(1, 2, 8, 64) # queries - (batch, heads, seq len, dimension of head)\n",
    "k = torch.randn(1, 2, 8, 64) # keys\n",
    "\n",
    "q = q[:, :, [seq_idx], :]\n",
    "k[:, :, seq_idx+1:, :] = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_rotated, k_rotated = rotary_emb.rotate_queries_with_cached_keys(q, k) # pass all cached keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_double_rotated, k_double_rotated = rotary_emb.rotate_queries_with_cached_keys(q_rotated, k_rotated) # pass all cached keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.allclose(k_double_rotated[:, :, 0, :], k_rotated[:, :, 0, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8349,  0.1951, -1.3999, -0.0461,  1.8644,  0.8243,  0.5217,\n",
       "           0.0165, -0.1531, -1.5532,  0.0227, -0.6695, -0.4033, -1.7691,\n",
       "           0.4640,  1.5651,  0.0600,  1.5951,  0.9842,  0.4906,  0.9918,\n",
       "          -0.5005, -3.1655,  0.0134,  0.8975, -1.4514,  0.1484, -0.2623,\n",
       "           0.6115,  2.1162,  0.5849, -0.7527,  0.1158, -0.4192,  0.6878,\n",
       "           0.4351, -0.2205, -1.1369,  0.7604,  1.0182,  0.6992, -0.6007,\n",
       "          -1.6325,  0.0287,  0.5296, -1.2345, -0.7244, -0.5330, -1.7051,\n",
       "           1.2483,  0.6185,  0.1223,  1.1791, -0.2623, -0.7074, -0.8204,\n",
       "          -0.5255, -0.3207, -0.9353, -0.3042,  0.5654,  0.2660,  0.8855,\n",
       "          -0.8075],\n",
       "         [-0.0882,  0.3458,  0.3276, -0.4652, -1.5064, -0.8110, -1.6426,\n",
       "          -0.4660,  0.8792, -2.8825, -1.5115, -0.6945,  1.9446, -1.5879,\n",
       "          -0.0137, -0.6306, -0.5265,  0.1023,  1.1742, -0.1347,  0.8002,\n",
       "          -0.5413,  0.4216,  1.1626, -0.4917,  0.8571,  1.1744, -0.5008,\n",
       "          -0.1364, -0.2443,  3.5168, -0.1269,  1.3594, -0.9364,  2.5798,\n",
       "          -1.2951,  0.4950, -0.4767, -1.7088,  0.8105, -0.9781,  0.9162,\n",
       "          -0.3585, -0.4184,  0.5047, -1.7451, -2.0133, -1.2795,  0.2554,\n",
       "          -0.2647,  0.3428, -1.6583,  0.7557, -0.6268, -0.1011,  0.5849,\n",
       "           0.2331, -0.9896,  0.1761, -0.2185, -1.7714,  0.4587,  0.5971,\n",
       "           0.6680]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_rotated[:, :, 1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8.2724e-01,  1.6494e+00, -1.1598e+00, -7.8542e-01,  1.5156e+00,\n",
       "           1.3633e+00,  5.1060e-01,  1.0855e-01,  2.7415e-03, -1.5607e+00,\n",
       "           6.0266e-02, -6.6716e-01, -3.4714e-01, -1.7810e+00,  4.3605e-01,\n",
       "           1.5731e+00,  4.4025e-02,  1.5956e+00,  9.8138e-01,  4.9612e-01,\n",
       "           9.9339e-01, -4.9738e-01, -3.1655e+00,  7.7229e-03,  8.9898e-01,\n",
       "          -1.4505e+00,  1.4860e-01, -2.6223e-01,  6.1085e-01,  2.1164e+00,\n",
       "           5.8504e-01, -7.5256e-01,  1.1581e-01, -4.1919e-01,  6.8779e-01,\n",
       "           4.3509e-01, -2.2048e-01, -1.1369e+00,  7.6039e-01,  1.0182e+00,\n",
       "           6.9916e-01, -6.0072e-01, -1.6325e+00,  2.8681e-02,  5.2958e-01,\n",
       "          -1.2345e+00, -7.2438e-01, -5.3301e-01, -1.7051e+00,  1.2483e+00,\n",
       "           6.1851e-01,  1.2232e-01,  1.1791e+00, -2.6227e-01, -7.0736e-01,\n",
       "          -8.2045e-01, -5.2549e-01, -3.2071e-01, -9.3528e-01, -3.0422e-01,\n",
       "           5.6540e-01,  2.6597e-01,  8.8553e-01, -8.0746e-01],\n",
       "         [-3.3865e-01,  1.1264e-01,  5.2515e-01, -2.1892e-01, -1.1795e+00,\n",
       "          -1.2392e+00, -1.5343e+00, -7.4925e-01,  1.1626e+00, -2.7803e+00,\n",
       "          -1.4701e+00, -7.7831e-01,  1.9938e+00, -1.5256e+00, -2.4515e-03,\n",
       "          -6.3073e-01, -5.2754e-01,  9.7049e-02,  1.1750e+00, -1.2813e-01,\n",
       "           8.0191e-01, -5.3875e-01,  4.1958e-01,  1.1633e+00, -4.9254e-01,\n",
       "           8.5658e-01,  1.1747e+00, -5.0012e-01, -1.3632e-01, -2.4438e-01,\n",
       "           3.5168e+00, -1.2624e-01,  1.3594e+00, -9.3638e-01,  2.5798e+00,\n",
       "          -1.2951e+00,  4.9496e-01, -4.7667e-01, -1.7088e+00,  8.1046e-01,\n",
       "          -9.7814e-01,  9.1621e-01, -3.5848e-01, -4.1838e-01,  5.0468e-01,\n",
       "          -1.7451e+00, -2.0133e+00, -1.2795e+00,  2.5543e-01, -2.6474e-01,\n",
       "           3.4280e-01, -1.6583e+00,  7.5567e-01, -6.2684e-01, -1.0110e-01,\n",
       "           5.8486e-01,  2.3307e-01, -9.8965e-01,  1.7611e-01, -2.1854e-01,\n",
       "          -1.7714e+00,  4.5874e-01,  5.9710e-01,  6.6804e-01]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_double_rotated[:, :, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
