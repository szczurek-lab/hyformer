{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os, logging, argparse, sys\n",
    "\n",
    "import torch\n",
    "\n",
    "from hyformer.configs.dataset import DatasetConfig\n",
    "from hyformer.configs.tokenizer import TokenizerConfig\n",
    "from hyformer.configs.model import ModelConfig\n",
    "from hyformer.configs.trainer import TrainerConfig\n",
    "\n",
    "from hyformer.utils.datasets.auto import AutoDataset\n",
    "from hyformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from hyformer.models.auto import AutoModel\n",
    "\n",
    "from hyformer.trainers.trainer import Trainer\n",
    "\n",
    "from hyformer.utils.reproducibility import set_seed\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/lustre/groups/aih/hyformer/data\"\n",
    "\n",
    "DATASET_CONFIG_PATH = \"configs/datasets/guacamol/config.json\"\n",
    "TOKENIZER_CONFIG_PATH = \"configs/tokenizers/smiles/guacamol/config.json\"\n",
    "MODEL_CONFIG_PATH = \"configs/models/guacamol/hyformer_small/config.json\"\n",
    "TRAINER_CONFIG_PATH = \"configs/trainers/distribution_learning/guacamol/lm/config.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configurations\n",
    "dataset_config = DatasetConfig.from_config_filepath(DATASET_CONFIG_PATH)\n",
    "tokenizer_config = TokenizerConfig.from_config_filepath(TOKENIZER_CONFIG_PATH)\n",
    "model_config = ModelConfig.from_config_filepath(MODEL_CONFIG_PATH)\n",
    "trainer_config = TrainerConfig.from_config_filepath(TRAINER_CONFIG_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we do prediction, we need to set the task to prediction\n",
    "model_config.num_prediction_tasks = 200\n",
    "prediction_task_type = \"regression\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "train_dataset = AutoDataset.from_config(dataset_config, split='train', root=DATA_DIR)\n",
    "val_dataset = AutoDataset.from_config(dataset_config, split='val', root=DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_config(tokenizer_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the device\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyformer(\n",
       "  (token_embedding): Embedding(109, 256)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerLayer(\n",
       "      (attention_layer): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (relative_embedding): RotaryEmbedding()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (w3): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (w2): Linear(in_features=1024, out_features=256, bias=False)\n",
       "      )\n",
       "      (attention_layer_normalization): RMSNorm()\n",
       "      (feed_forward_normalization): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): RMSNorm()\n",
       "  (lm_head): Linear(in_features=256, out_features=109, bias=False)\n",
       "  (mlm_head): Linear(in_features=256, out_features=109, bias=False)\n",
       "  (prediction_head): PredictionHead(\n",
       "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (activation_fn): ReLU()\n",
       "    (dropout): Identity()\n",
       "    (out_proj): Linear(in_features=256, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = AutoModel.from_config(model_config, num_prediction_tasks=200, prediction_task_type=\"regression\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(tokenizer) == model.vocab_size, f\"Tokenizer vocab size {len(tokenizer)} does not match model embedding dim {model.embedding_dim}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    config=trainer_config,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_loader = trainer.create_loader(train_dataset, shuffle=True, tasks={'prediction': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch = next(iter(trainer_loader))\n",
    "    batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "    output = model(**batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2357, device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [train_dataset[i]['data'] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCC(C)(C)Br', 'CCCN(CCc1cccc(-c2ccccc2)c1)C(=O)C1OC(C(=O)O)=CC(N)C1NC(C)=O']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[106, 102, 19, 19, 19, 4, 19, 5, 4, 19, 5, 18, 103],\n",
       "  [106,\n",
       "   102,\n",
       "   19,\n",
       "   19,\n",
       "   19,\n",
       "   23,\n",
       "   4,\n",
       "   19,\n",
       "   19,\n",
       "   97,\n",
       "   7,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   4,\n",
       "   6,\n",
       "   97,\n",
       "   8,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   97,\n",
       "   8,\n",
       "   5,\n",
       "   97,\n",
       "   7,\n",
       "   5,\n",
       "   19,\n",
       "   4,\n",
       "   16,\n",
       "   24,\n",
       "   5,\n",
       "   19,\n",
       "   7,\n",
       "   24,\n",
       "   19,\n",
       "   4,\n",
       "   19,\n",
       "   4,\n",
       "   16,\n",
       "   24,\n",
       "   5,\n",
       "   24,\n",
       "   5,\n",
       "   16,\n",
       "   19,\n",
       "   19,\n",
       "   4,\n",
       "   23,\n",
       "   5,\n",
       "   19,\n",
       "   7,\n",
       "   23,\n",
       "   19,\n",
       "   4,\n",
       "   19,\n",
       "   5,\n",
       "   16,\n",
       "   24,\n",
       "   103]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(samples, task='lm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_loader = trainer.create_loader(train_dataset, shuffle=True, tasks=trainer.config.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(trainer_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'task', 'attention_mask', 'input_labels', 'target'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[106, 102,  19,  ..., 104, 104, 104],\n",
       "        [106, 102,  19,  ..., 104, 104, 104],\n",
       "        [106, 102,  19,  ..., 104, 104, 104],\n",
       "        ...,\n",
       "        [106, 102,  24,  ..., 104, 104, 104],\n",
       "        [106, 102,  97,  ..., 104, 104, 104],\n",
       "        [106, 102,  24,  ..., 104, 104, 104]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lm'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attention_mask']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100, -100,   19,  ..., -100, -100, -100],\n",
       "        [-100, -100,   19,  ..., -100, -100, -100],\n",
       "        [-100, -100,   19,  ..., -100, -100, -100],\n",
       "        ...,\n",
       "        [-100, -100,   24,  ..., -100, -100, -100],\n",
       "        [-100, -100,   97,  ..., -100, -100, -100],\n",
       "        [-100, -100,   24,  ..., -100, -100, -100]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False,  True, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'][0] == 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['attention_mask'][0][batch['input_ids'][0] == 103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyformer(\n",
       "  (token_embedding): Embedding(511, 256)\n",
       "  (layers): ModuleList(\n",
       "    (0-5): 6 x TransformerLayer(\n",
       "      (attention_layer): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (k_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (v_proj): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (out): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (relative_embedding): RotaryEmbedding()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (w3): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        (w2): Linear(in_features=1024, out_features=256, bias=False)\n",
       "      )\n",
       "      (attention_layer_normalization): RMSNorm()\n",
       "      (feed_forward_normalization): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): RMSNorm()\n",
       "  (lm_head): Linear(in_features=256, out_features=511, bias=False)\n",
       "  (mlm_head): Linear(in_features=256, out_features=511, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#': 0,\n",
       " '%10': 1,\n",
       " '%11': 2,\n",
       " '%12': 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " '-': 6,\n",
       " '1': 7,\n",
       " '2': 8,\n",
       " '3': 9,\n",
       " '4': 10,\n",
       " '5': 11,\n",
       " '6': 12,\n",
       " '7': 13,\n",
       " '8': 14,\n",
       " '9': 15,\n",
       " '=': 16,\n",
       " 'B': 17,\n",
       " 'Br': 18,\n",
       " 'C': 19,\n",
       " 'Cl': 20,\n",
       " 'F': 21,\n",
       " 'I': 22,\n",
       " 'N': 23,\n",
       " 'O': 24,\n",
       " 'P': 25,\n",
       " 'S': 26,\n",
       " '[B-]': 27,\n",
       " '[BH-]': 28,\n",
       " '[BH2-]': 29,\n",
       " '[BH3-]': 30,\n",
       " '[B]': 31,\n",
       " '[Br+2]': 32,\n",
       " '[Br-]': 33,\n",
       " '[C+]': 34,\n",
       " '[C-]': 35,\n",
       " '[CH+]': 36,\n",
       " '[CH-]': 37,\n",
       " '[CH2+]': 38,\n",
       " '[CH2]': 39,\n",
       " '[CH]': 40,\n",
       " '[Cl+2]': 41,\n",
       " '[Cl+3]': 42,\n",
       " '[Cl+]': 43,\n",
       " '[Cl-]': 44,\n",
       " '[F+]': 45,\n",
       " '[F-]': 46,\n",
       " '[H]': 47,\n",
       " '[I+2]': 48,\n",
       " '[I+3]': 49,\n",
       " '[I+]': 50,\n",
       " '[I-]': 51,\n",
       " '[IH2]': 52,\n",
       " '[N+]': 53,\n",
       " '[N-]': 54,\n",
       " '[NH+]': 55,\n",
       " '[NH-]': 56,\n",
       " '[NH2+]': 57,\n",
       " '[NH3+]': 58,\n",
       " '[N]': 59,\n",
       " '[O+]': 60,\n",
       " '[O-]': 61,\n",
       " '[OH+]': 62,\n",
       " '[O]': 63,\n",
       " '[P+]': 64,\n",
       " '[P-]': 65,\n",
       " '[PH2+]': 66,\n",
       " '[PH]': 67,\n",
       " '[S+]': 68,\n",
       " '[S-]': 69,\n",
       " '[SH+]': 70,\n",
       " '[SH-]': 71,\n",
       " '[SH]': 72,\n",
       " '[Se+]': 73,\n",
       " '[Se-]': 74,\n",
       " '[SeH2]': 75,\n",
       " '[SeH]': 76,\n",
       " '[Se]': 77,\n",
       " '[Si-]': 78,\n",
       " '[SiH-]': 79,\n",
       " '[SiH2]': 80,\n",
       " '[SiH]': 81,\n",
       " '[Si]': 82,\n",
       " '[b-]': 83,\n",
       " '[c+]': 84,\n",
       " '[c-]': 85,\n",
       " '[cH+]': 86,\n",
       " '[cH-]': 87,\n",
       " '[n+]': 88,\n",
       " '[n-]': 89,\n",
       " '[nH+]': 90,\n",
       " '[nH]': 91,\n",
       " '[o+]': 92,\n",
       " '[s+]': 93,\n",
       " '[se+]': 94,\n",
       " '[se]': 95,\n",
       " 'b': 96,\n",
       " 'c': 97,\n",
       " 'n': 98,\n",
       " 'o': 99,\n",
       " 'p': 100,\n",
       " 's': 101,\n",
       " '<s>': 102,\n",
       " '</s>': 103,\n",
       " '<pad>': 104,\n",
       " '<mask>': 105,\n",
       " '<lm>': 106,\n",
       " '<cls>': 107,\n",
       " '<mlm>': 108}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7c71a9ca254693b6f39bb84a2174f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1273104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "for idx in tqdm(range(len(train_dataset))):\n",
    "    sample = train_dataset[idx]\n",
    "    input_ids = tokenizer(sample['data'], task='lm')['input_ids']\n",
    "    sample_tokens = tokenizer.decode(torch.tensor(input_ids).reshape(1, -1))\n",
    "    if sample['data'] != sample_tokens:\n",
    "        print(f\"Mismatch at index {idx}\")\n",
    "        print(f\"Original: {sample['data']}\")\n",
    "        print(f\"Decoded: {sample_tokens}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n",
      "RMSNorm input: dtype=torch.float32, shape=torch.Size([1024, 128, 256])\n",
      "Epsilon: 1e-06\n",
      "After float conversion: dtype=torch.float32\n",
      "After norm: dtype=torch.float32, contains NaN=False\n",
      "After type_as: dtype=torch.float32\n",
      "Final output: dtype=torch.float32\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    batch = next(iter(trainer_loader))\n",
    "    batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "    output = model(**batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'Tensor' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(trainer_loader))\n\u001b[1;32m      3\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m----> 4\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre/groups/aih/hyformer/env/hyformer_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre/groups/aih/hyformer/env/hyformer_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/ictstr01/home/aih/adam.izdebski/projects/hyformer/hyformer/models/hyformer.py:173\u001b[0m, in \u001b[0;36mHyformer.forward\u001b[0;34m(self, input_ids, task, attention_mask, next_token_only, use_cache, input_labels, target, return_loss, loss_fn_reduction, nan_target_idx, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     _is_causal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     _attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\n\u001b[0;32m--> 173\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnext_token_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnext_token_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    182\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/ictstr01/home/aih/adam.izdebski/projects/hyformer/hyformer/models/llama_backbone.py:88\u001b[0m, in \u001b[0;36mLLAMABackbone.forward\u001b[0;34m(self, input_ids, is_causal, attention_mask, cls_context, next_token_only, use_cache)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# apply the transformer layers\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m---> 88\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# apply the layer normalization\u001b[39;00m\n\u001b[1;32m     96\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(x)\n",
      "File \u001b[0;32m/lustre/groups/aih/hyformer/env/hyformer_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre/groups/aih/hyformer/env/hyformer_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/ictstr01/home/aih/adam.izdebski/projects/hyformer/hyformer/models/layers/transformer_layer.py:53\u001b[0m, in \u001b[0;36mTransformerLayer.forward\u001b[0;34m(self, x, is_causal, attention_mask, past_key_value, use_cache)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     45\u001b[0m     x: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     use_cache: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     50\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m     51\u001b[0m     _residual \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     52\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_layer(\n\u001b[0;32m---> 53\u001b[0m         x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_layer_normalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     54\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m     55\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m     56\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m     57\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache\n\u001b[1;32m     58\u001b[0m         )\n\u001b[1;32m     59\u001b[0m     x \u001b[38;5;241m=\u001b[39m _residual \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_normalization(x))\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/lustre/groups/aih/hyformer/env/hyformer_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/lustre/groups/aih/hyformer/env/hyformer_experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/ictstr01/home/aih/adam.izdebski/projects/hyformer/hyformer/models/layers/layer_norm.py:25\u001b[0m, in \u001b[0;36mRMSNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 25\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype_as(x)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\n",
      "File \u001b[0;32m/ictstr01/home/aih/adam.izdebski/projects/hyformer/hyformer/models/layers/layer_norm.py:22\u001b[0m, in \u001b[0;36mRMSNorm._norm\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'Tensor' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "trainer_loader = trainer.create_loader(train_dataset, shuffle=True, tasks=trainer.config.tasks)\n",
    "batch = next(iter(trainer_loader))\n",
    "batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "output = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings': tensor([[[ 0.4813,  0.4716, -0.0284,  ...,  1.9936, -0.9211,  0.8080],\n",
       "          [ 0.1341,  0.4819,  0.7443,  ...,  2.5249, -0.2914,  0.8500],\n",
       "          [ 0.4777,  1.0220,  1.1169,  ...,  1.5697, -0.4688,  0.7853],\n",
       "          ...,\n",
       "          [ 0.9571,  0.1316,  0.2807,  ..., -2.0248,  0.6369,  0.0666],\n",
       "          [ 0.8692,  0.1617,  0.2442,  ..., -2.0281,  0.6831,  0.0247],\n",
       "          [ 0.8092,  0.2280,  0.2257,  ..., -2.0261,  0.6963, -0.0322]],\n",
       " \n",
       "         [[ 0.4813,  0.4716, -0.0284,  ...,  1.9936, -0.9211,  0.8080],\n",
       "          [ 0.1341,  0.4819,  0.7443,  ...,  2.5249, -0.2914,  0.8500],\n",
       "          [ 0.4777,  1.0220,  1.1169,  ...,  1.5697, -0.4688,  0.7853],\n",
       "          ...,\n",
       "          [-0.8919, -0.8109, -0.2490,  ...,  1.2396, -0.8445,  0.0707],\n",
       "          [-0.9101, -0.7516, -0.2737,  ...,  1.3754, -0.8288,  0.0614],\n",
       "          [-0.8724, -0.7493, -0.2219,  ...,  1.4644, -0.7920,  0.0825]],\n",
       " \n",
       "         [[ 0.4813,  0.4716, -0.0284,  ...,  1.9936, -0.9211,  0.8080],\n",
       "          [ 0.1341,  0.4819,  0.7443,  ...,  2.5249, -0.2914,  0.8500],\n",
       "          [ 0.4777,  1.0220,  1.1169,  ...,  1.5697, -0.4688,  0.7853],\n",
       "          ...,\n",
       "          [ 0.4220, -0.2470, -1.7525,  ...,  0.0049, -0.7292, -0.0604],\n",
       "          [ 0.3445, -0.2287, -1.8818,  ...,  0.2099, -0.6670, -0.0255],\n",
       "          [ 0.2957, -0.1676, -1.9927,  ...,  0.3561, -0.6488,  0.0215]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.4813,  0.4716, -0.0284,  ...,  1.9936, -0.9211,  0.8080],\n",
       "          [ 0.1341,  0.4819,  0.7443,  ...,  2.5249, -0.2914,  0.8500],\n",
       "          [ 0.4777,  1.0220,  1.1169,  ...,  1.5697, -0.4688,  0.7853],\n",
       "          ...,\n",
       "          [ 0.0404, -1.2594, -0.8871,  ..., -0.1110,  0.6756, -0.5510],\n",
       "          [-0.0164, -1.1501, -1.0203,  ...,  0.0099,  0.5506, -0.5607],\n",
       "          [-0.0446, -1.1630, -1.0255,  ...,  0.0664,  0.5016, -0.5440]],\n",
       " \n",
       "         [[ 0.4813,  0.4716, -0.0284,  ...,  1.9936, -0.9211,  0.8080],\n",
       "          [ 0.1341,  0.4819,  0.7443,  ...,  2.5249, -0.2914,  0.8500],\n",
       "          [ 0.4777,  1.0220,  1.1169,  ...,  1.5697, -0.4688,  0.7853],\n",
       "          ...,\n",
       "          [-0.8177, -0.5918, -1.5502,  ..., -0.3756,  0.4260, -0.2351],\n",
       "          [-0.8133, -0.4745, -1.5937,  ..., -0.5424,  0.4382, -0.2827],\n",
       "          [-0.7710, -0.2985, -1.5912,  ..., -0.6460,  0.5396, -0.2793]],\n",
       " \n",
       "         [[ 0.4813,  0.4716, -0.0284,  ...,  1.9936, -0.9211,  0.8080],\n",
       "          [ 0.1341,  0.4819,  0.7443,  ...,  2.5249, -0.2914,  0.8500],\n",
       "          [ 0.4777,  1.0220,  1.1169,  ...,  1.5697, -0.4688,  0.7853],\n",
       "          ...,\n",
       "          [-0.0660, -0.9797, -0.2189,  ...,  0.3104,  1.1898, -0.7304],\n",
       "          [-0.0744, -1.0786, -0.0745,  ...,  0.3606,  1.1070, -0.6597],\n",
       "          [-0.1239, -1.1875, -0.0048,  ...,  0.4450,  1.0386, -0.7182]]],\n",
       "        device='cuda:0'),\n",
       " 'logits': tensor([[[-1.2240, -1.4218, -0.0332,  ...,  4.5196,  1.5617,  0.6793],\n",
       "          [-1.6464, -0.7405, -0.5850,  ...,  3.4153,  1.3517,  0.2226],\n",
       "          [-1.1694, -0.6742, -1.0468,  ...,  2.7474,  1.3177, -0.4456],\n",
       "          ...,\n",
       "          [ 0.9636, -0.6090, -1.3536,  ..., -2.5403,  0.1821, -2.2171],\n",
       "          [ 0.9853, -0.5690, -1.3419,  ..., -2.5673,  0.1161, -2.1272],\n",
       "          [ 1.0315, -0.5364, -1.4003,  ..., -2.6566,  0.0972, -2.1011]],\n",
       " \n",
       "         [[-1.2240, -1.4218, -0.0332,  ...,  4.5196,  1.5617,  0.6793],\n",
       "          [-1.6464, -0.7405, -0.5850,  ...,  3.4153,  1.3517,  0.2226],\n",
       "          [-1.1694, -0.6742, -1.0468,  ...,  2.7474,  1.3177, -0.4456],\n",
       "          ...,\n",
       "          [-0.1626, -1.8919, -1.5511,  ..., -1.6422,  0.3026,  1.2741],\n",
       "          [-0.1332, -1.7912, -1.5576,  ..., -1.5505,  0.4332,  1.3137],\n",
       "          [-0.0658, -1.6915, -1.5961,  ..., -1.4385,  0.5582,  1.2860]],\n",
       " \n",
       "         [[-1.2240, -1.4218, -0.0332,  ...,  4.5196,  1.5617,  0.6793],\n",
       "          [-1.6464, -0.7405, -0.5850,  ...,  3.4153,  1.3517,  0.2226],\n",
       "          [-1.1694, -0.6742, -1.0468,  ...,  2.7474,  1.3177, -0.4456],\n",
       "          ...,\n",
       "          [-1.1201,  0.4698,  0.2325,  ..., -0.7010,  0.4126,  0.3170],\n",
       "          [-0.8942,  0.5595,  0.1596,  ..., -0.8141,  0.4312,  0.3498],\n",
       "          [-0.7596,  0.5877,  0.1422,  ..., -0.8405,  0.4225,  0.3658]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.2240, -1.4218, -0.0332,  ...,  4.5196,  1.5617,  0.6793],\n",
       "          [-1.6464, -0.7405, -0.5850,  ...,  3.4153,  1.3517,  0.2226],\n",
       "          [-1.1694, -0.6742, -1.0468,  ...,  2.7474,  1.3177, -0.4456],\n",
       "          ...,\n",
       "          [-0.6487, -0.2548, -0.3483,  ..., -2.5183,  0.8537, -2.6384],\n",
       "          [-0.6321, -0.1855, -0.2726,  ..., -2.4620,  0.8764, -2.6304],\n",
       "          [-0.6786, -0.1208, -0.1839,  ..., -2.4561,  0.9078, -2.5430]],\n",
       " \n",
       "         [[-1.2240, -1.4218, -0.0332,  ...,  4.5196,  1.5617,  0.6793],\n",
       "          [-1.6464, -0.7405, -0.5850,  ...,  3.4153,  1.3517,  0.2226],\n",
       "          [-1.1694, -0.6742, -1.0468,  ...,  2.7474,  1.3177, -0.4456],\n",
       "          ...,\n",
       "          [-0.0808,  2.4350,  1.0760,  ..., -1.0296,  0.2475, -0.9793],\n",
       "          [-0.1309,  2.3566,  1.1245,  ..., -0.9525,  0.2340, -0.9826],\n",
       "          [-0.1572,  2.3396,  1.1331,  ..., -0.9099,  0.3174, -0.9652]],\n",
       " \n",
       "         [[-1.2240, -1.4218, -0.0332,  ...,  4.5196,  1.5617,  0.6793],\n",
       "          [-1.6464, -0.7405, -0.5850,  ...,  3.4153,  1.3517,  0.2226],\n",
       "          [-1.1694, -0.6742, -1.0468,  ...,  2.7474,  1.3177, -0.4456],\n",
       "          ...,\n",
       "          [ 0.0668, -2.1222, -0.7422,  ..., -0.5895,  2.0435, -1.3414],\n",
       "          [-0.0266, -2.0554, -0.6448,  ..., -0.6050,  2.1348, -1.4097],\n",
       "          [-0.1298, -1.9659, -0.5869,  ..., -0.6666,  2.2439, -1.4118]]],\n",
       "        device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
       " 'task': 'lm',\n",
       " 'loss': tensor(5.2305, device='cuda:0')}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Use a minimal batch with a single short sequence\n",
    "   simple_input = {\"input_ids\": torch.tensor([[1, 2, 3]]).to(device), \n",
    "                   \"attention_mask\": torch.tensor([[1, 1, 1]]).to(device),\n",
    "                   \"task\": \"lm\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from hyformer.utils.datasets.sequence import SequenceDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load peptide dataset\n",
    "\n",
    "data_filepath = \"/lustre/groups/aih/hyformer/data_proprietary/peptides/mic/raw/mic_data.csv\"\n",
    "\n",
    "_df = pd.read_csv(data_filepath, index_col=0)\n",
    "data = _df['sequence']\n",
    "target = _df['value']\n",
    "\n",
    "dataset = SequenceDataset(data=data, target=target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'AAAAAAAAAAGIGKFLHSAKKFGKAFVGEIMNS', 'target': 2.099950350098421}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENIZER_CONFIG_PATH = \"configs/tokenizers/amino_acid/config.json\"\n",
    "\n",
    "tokenizer_config = TokenizerConfig.from_config_filepath(TOKENIZER_CONFIG_PATH)\n",
    "tokenizer = AutoTokenizer.from_config(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289b9b3da193462a893e737ddafb964b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4546 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    sample = dataset[idx]\n",
    "    input_ids = tokenizer(sample['data'], task='lm')['input_ids']\n",
    "    sample_tokens = tokenizer.decode(torch.tensor(input_ids).reshape(1, -1))\n",
    "    if sample['data'] != sample_tokens:\n",
    "        print(f\"Mismatch at index {idx}\")\n",
    "        print(f\"Original: {sample['data']}\")\n",
    "        print(f\"Decoded: {sample_tokens}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'YWRWRW', 'target': 1.278935990813498}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
