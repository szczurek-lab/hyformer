{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODOs:\n",
    "    - extract Guacamol data using not pickling\n",
    "    - run training and debug sucesfully \n",
    "    - get all tokenn\n",
    "    - get a proper env - env.yml (with minimal requirements)\n",
    "    - reproduce Guacamol benchmark for serious\n",
    "    - actually, I need to redo the splits for Fibrosis\n",
    "    - download UniMol pre-train data or other pre-train data (GuacaMol) and save it using: smiles_array = np.array(smiles_list, dtype='<U50'), to disable pickle. \n",
    "    - save data with numpy_version=np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from hyformer.configs.dataset import DatasetConfig\n",
    "from hyformer.configs.tokenizer import TokenizerConfig\n",
    "from hyformer.configs.model import ModelConfig\n",
    "from hyformer.configs.trainer import TrainerConfig\n",
    "\n",
    "from hyformer.utils.datasets.sequence import SequenceDataset\n",
    "from hyformer.utils.datasets.auto import AutoDataset\n",
    "from hyformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from hyformer.models.auto import AutoModel\n",
    "from hyformer.trainers.trainer import Trainer\n",
    "\n",
    "# auxiliary \n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# reload magic\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:39:47,458 - root - INFO - Logging is set up and working!</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Create a custom handler for notebook display\n",
    "class NotebookHandler(logging.Handler):\n",
    "    def __init__(self, level=logging.INFO):\n",
    "        super().__init__(level)\n",
    "        self.logs = []\n",
    "        \n",
    "    def emit(self, record):\n",
    "        log_entry = self.format(record)\n",
    "        self.logs.append(log_entry)\n",
    "        \n",
    "        # Create different CSS classes based on log level\n",
    "        level_css = {\n",
    "            'DEBUG': 'color: #6c757d;',  # gray\n",
    "            'INFO': 'color: #0d6efd;',   # blue\n",
    "            'WARNING': 'color: #ffc107; font-weight: bold;',  # yellow\n",
    "            'ERROR': 'color: #dc3545; font-weight: bold;',    # red\n",
    "            'CRITICAL': 'color: #fff; background-color: #dc3545; font-weight: bold; padding: 2px 5px;'  # white on red\n",
    "        }\n",
    "        \n",
    "        css = level_css.get(record.levelname, '')\n",
    "        display(HTML(f'<pre style=\"{css}\">{log_entry}</pre>'))\n",
    "    \n",
    "    def get_logs(self):\n",
    "        return self.logs\n",
    "\n",
    "# Configure root logger and Trainer's logger\n",
    "def setup_notebook_logging(level=logging.INFO):\n",
    "    # Clear any existing handlers\n",
    "    root_logger = logging.getLogger()\n",
    "    for handler in root_logger.handlers[:]:\n",
    "        root_logger.removeHandler(handler)\n",
    "    \n",
    "    # Configure formatter\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    \n",
    "    # Setup notebook handler\n",
    "    notebook_handler = NotebookHandler(level=level)\n",
    "    notebook_handler.setFormatter(formatter)\n",
    "    root_logger.addHandler(notebook_handler)\n",
    "    root_logger.setLevel(level)\n",
    "    \n",
    "    # Also add a handler for the hyformer.trainers console logger\n",
    "    trainer_logger = logging.getLogger('hyformer.trainers')\n",
    "    trainer_logger.addHandler(notebook_handler)\n",
    "    trainer_logger.setLevel(level)\n",
    "    \n",
    "    return notebook_handler\n",
    "\n",
    "# Call this function to set up logging\n",
    "notebook_logs = setup_notebook_logging(logging.INFO)\n",
    "\n",
    "# Test the logger\n",
    "logging.info(\"Logging is set up and working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set the notebook output directory to project root\n",
    "\n",
    "REPOSITORY_DIR = '/home/aih/adam.izdebski/projects/hyformer'\n",
    "os.chdir(REPOSITORY_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OUT_DIR = \"results/notebooks/test\"\n",
    "DATA_DIR = \"/lustre/groups/aih/hyformer/data\"\n",
    "\n",
    "DATASET_CONFIG_FILEPATH = \"configs/datasets/fibrosis/standard_smiles/random_transfer/config.json\"\n",
    "TOKENIZER_CONFIG_FILEPATH = \"configs/tokenizers/smiles/config.json\"\n",
    "MODEL_CONFIG_FILEPATH = \"configs/models/hyformer_tiny/config.json\"\n",
    "TRAINER_CONFIG_FILEPATH = \"configs/trainers/pretrain_lm_mlm_physchem_debug/config.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load exemplary SMILES with random labels for testing\n",
    " \n",
    "smiles_list = [\n",
    "    \"Cc1nc[nH]c1C1CC(=O)Nc2c1c(C)nn2C1CCCCC1\",\n",
    "    \"CCCCNC(=O)NS(=O)(=O)c1ccc(C)cc1\",\n",
    "    \"COc1ccc(Nc2c3c4c(c(Br)ccc4n(C)c2=O)C(=O)c2ccccc2-3)cc1\",\n",
    "    \"Cn1c(=O)c2c(ncn2CC2OCCO2)n(C)c1=O\",\n",
    "    \"NC12CC3CC(C1)CC(n1cncn1)(C3)C2\",\n",
    "    \"NC(=O)NN=Cc1ccc([N+](=O)[O-])o1\",\n",
    "    \"CC1=C(C(=O)OC(C)C)C(c2ccccn2)C2=C(CC(c3ccccc3)CC2=O)N1\",\n",
    "    \"CCc1c2c(nc3ccc(OC(=O)N4CCC(N5CCCCC5)CC4)cc13)-c1cc3c(c(=O)n1C2)COC(=O)C3(O)CC\",\n",
    "    \"Cc1nc(CN(C)C(=O)C2CC=CCC2)no1\",\n",
    "    \"COc1ccnc(C[S+]([O-])c2nc3ccc(-n4cccc4)cc3[nH]2)c1C\",\n",
    "    \"CCCCC(CC)COC(=O)C=Cc1ccc(OC)cc1\",\n",
    "    \"COCCOC(=O)C1=C(C)NC(C)=C(C(=O)OC(C)C)C1c1cccc([N+](=O)[O-])c1\",\n",
    "    \"Cc1ccc2c(c1)N(CCO)C(=Cc1ccc[n+](C)c1)S2\",\n",
    "    \"O=C(c1ccccn1)C1CCCN(C2CCC3(CCNCC3)CC2)C1\",\n",
    "    \"CCC(=O)OC(OP(=O)(CCCCc1ccccc1)CC(=O)N1CC(C2CCCCC2)CC1C(=O)O)C(C)C\",\n",
    "    \"CS(=O)(=O)Nc1ccc([N+](=O)[O-])cc1Oc1ccccc1\"\n",
    "]\n",
    "\n",
    "target_list = [random.randint(0, 1) for _ in smiles_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "\n",
    "# dataset_config = DatasetConfig.from_config_file(DATASET_CONFIG_FILEPATH)\n",
    "# dataset = AutoDataset.from_config(dataset_config, split=\"test\", root=DATA_DIR)\n",
    "\n",
    "train_dataset = SequenceDataset(data=smiles_list, target=np.array(target_list, dtype=np.int32))\n",
    "val_dataset = SequenceDataset(data=smiles_list, target=np.array(target_list, dtype=np.int32))\n",
    "test_dataset = SequenceDataset(data=smiles_list, target=np.array(target_list, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "\n",
    "tokenizer_config = TokenizerConfig.from_config_file(TOKENIZER_CONFIG_FILEPATH)\n",
    "tokenizer = AutoTokenizer.from_config(tokenizer_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 511\n"
     ]
    }
   ],
   "source": [
    "# get vocab size\n",
    "\n",
    "vocab_size = len(tokenizer)\n",
    "print(f\"Vocab size: {vocab_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyformer(\n",
       "  (token_embedding): Embedding(511, 16)\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerLayer(\n",
       "      (attention_layer): Attention(\n",
       "        (q_proj): Linear(in_features=16, out_features=16, bias=False)\n",
       "        (k_proj): Linear(in_features=16, out_features=16, bias=False)\n",
       "        (v_proj): Linear(in_features=16, out_features=16, bias=False)\n",
       "        (out): Linear(in_features=16, out_features=16, bias=False)\n",
       "        (relative_embedding): RotaryEmbedding()\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=16, out_features=256, bias=False)\n",
       "        (w3): Linear(in_features=16, out_features=256, bias=False)\n",
       "        (w2): Linear(in_features=256, out_features=16, bias=False)\n",
       "      )\n",
       "      (attention_layer_normalization): RMSNorm()\n",
       "      (feed_forward_normalization): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): RMSNorm()\n",
       "  (lm_head): Linear(in_features=16, out_features=511, bias=False)\n",
       "  (mlm_head): Linear(in_features=16, out_features=511, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "model_config = ModelConfig.from_config_file(MODEL_CONFIG_FILEPATH)\n",
    "model = AutoModel.from_config(model_config)\n",
    "model.to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:41:11,844 - hyformer.trainers.trainer - INFO - Using worker seed: 42</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:41:11,844 - hyformer.trainers.trainer - INFO - Using worker seed: 42</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:41:11,844 - hyformer.trainers.trainer - INFO - Using worker seed: 42</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:41:11,844 - hyformer.trainers.trainer - INFO - Using worker seed: 42</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:41:11,844 - hyformer.trainers.trainer - INFO - Using worker seed: 42</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trainer \n",
    "\n",
    "trainer_config = TrainerConfig.from_config_file(TRAINER_CONFIG_FILEPATH)\n",
    "trainer = Trainer.from_config(config=trainer_config, model=model, tokenizer=tokenizer, device=device, out_dir=OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in thread QueueFeederThread:\n",
      "QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "        queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "Exception in thread QueueFeederThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    reader_close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self._close()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    self.run()\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/threading.py\", line 953, in run\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/lustre/groups/aih/hyformer/env/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n",
      "    queue_sem.release()\n",
      "ValueError: semaphore or lock released too many times\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:17,677 - hyformer.trainers.trainer - INFO - Epoch 0, Step 0: loss 6.1623, lr 0.000000, tokens/s 2.74</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:17,677 - hyformer.trainers.trainer - INFO - Epoch 0, Step 0: loss 6.1623, lr 0.000000, tokens/s 2.74</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:17,677 - hyformer.trainers.trainer - INFO - Epoch 0, Step 0: loss 6.1623, lr 0.000000, tokens/s 2.74</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:17,677 - hyformer.trainers.trainer - INFO - Epoch 0, Step 0: loss 6.1623, lr 0.000000, tokens/s 2.74</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:17,677 - hyformer.trainers.trainer - INFO - Epoch 0, Step 0: loss 6.1623, lr 0.000000, tokens/s 2.74</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:24,093 - hyformer.trainers.trainer - INFO - Epoch 0, Step 1: loss 6.1728, lr 0.000000, tokens/s 39.94</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:24,093 - hyformer.trainers.trainer - INFO - Epoch 0, Step 1: loss 6.1728, lr 0.000000, tokens/s 39.94</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:24,093 - hyformer.trainers.trainer - INFO - Epoch 0, Step 1: loss 6.1728, lr 0.000000, tokens/s 39.94</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:24,093 - hyformer.trainers.trainer - INFO - Epoch 0, Step 1: loss 6.1728, lr 0.000000, tokens/s 39.94</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:24,093 - hyformer.trainers.trainer - INFO - Epoch 0, Step 1: loss 6.1728, lr 0.000000, tokens/s 39.94</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:30,100 - hyformer.trainers.trainer - INFO - Epoch 0, Step 2: loss 6.1765, lr 0.000000, tokens/s 26.66</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:30,100 - hyformer.trainers.trainer - INFO - Epoch 0, Step 2: loss 6.1765, lr 0.000000, tokens/s 26.66</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:30,100 - hyformer.trainers.trainer - INFO - Epoch 0, Step 2: loss 6.1765, lr 0.000000, tokens/s 26.66</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:30,100 - hyformer.trainers.trainer - INFO - Epoch 0, Step 2: loss 6.1765, lr 0.000000, tokens/s 26.66</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:30,100 - hyformer.trainers.trainer - INFO - Epoch 0, Step 2: loss 6.1765, lr 0.000000, tokens/s 26.66</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:37,024 - hyformer.trainers.trainer - INFO - Epoch 0, Step 3: loss 6.1778, lr 0.000000, tokens/s 50.88</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:37,024 - hyformer.trainers.trainer - INFO - Epoch 0, Step 3: loss 6.1778, lr 0.000000, tokens/s 50.88</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:37,024 - hyformer.trainers.trainer - INFO - Epoch 0, Step 3: loss 6.1778, lr 0.000000, tokens/s 50.88</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:37,024 - hyformer.trainers.trainer - INFO - Epoch 0, Step 3: loss 6.1778, lr 0.000000, tokens/s 50.88</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:37,024 - hyformer.trainers.trainer - INFO - Epoch 0, Step 3: loss 6.1778, lr 0.000000, tokens/s 50.88</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-03 17:43:40,977] torch._dynamo.convert_frame: [WARNING] torch._dynamo hit config.cache_size_limit (8)\n",
      "[2025-04-03 17:43:40,977] torch._dynamo.convert_frame: [WARNING]    function: '__init__' (/ictstr01/home/aih/adam.izdebski/projects/hyformer/hyformer/models/utils.py:35)\n",
      "[2025-04-03 17:43:40,977] torch._dynamo.convert_frame: [WARNING]    last reason: ___check_global_state()\n",
      "[2025-04-03 17:43:40,977] torch._dynamo.convert_frame: [WARNING] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "[2025-04-03 17:43:40,977] torch._dynamo.convert_frame: [WARNING] To diagnose recompilation issues, see https://pytorch.org/docs/master/compile/troubleshooting.html.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,786 - hyformer.trainers.trainer - INFO - Epoch 0: val_loss 6.1783</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,786 - hyformer.trainers.trainer - INFO - Epoch 0: val_loss 6.1783</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,786 - hyformer.trainers.trainer - INFO - Epoch 0: val_loss 6.1783</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,786 - hyformer.trainers.trainer - INFO - Epoch 0: val_loss 6.1783</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,786 - hyformer.trainers.trainer - INFO - Epoch 0: val_loss 6.1783</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,791 - hyformer.trainers.trainer - INFO -   - lm loss: 6.1783 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,791 - hyformer.trainers.trainer - INFO -   - lm loss: 6.1783 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,791 - hyformer.trainers.trainer - INFO -   - lm loss: 6.1783 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,791 - hyformer.trainers.trainer - INFO -   - lm loss: 6.1783 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:46,791 - hyformer.trainers.trainer - INFO -   - lm loss: 6.1783 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,012 - hyformer.trainers.trainer - INFO - Epoch 1, Step 0: loss 6.1703, lr 0.000667, tokens/s 53100.59</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,012 - hyformer.trainers.trainer - INFO - Epoch 1, Step 0: loss 6.1703, lr 0.000667, tokens/s 53100.59</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,012 - hyformer.trainers.trainer - INFO - Epoch 1, Step 0: loss 6.1703, lr 0.000667, tokens/s 53100.59</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,012 - hyformer.trainers.trainer - INFO - Epoch 1, Step 0: loss 6.1703, lr 0.000667, tokens/s 53100.59</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,012 - hyformer.trainers.trainer - INFO - Epoch 1, Step 0: loss 6.1703, lr 0.000667, tokens/s 53100.59</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,022 - hyformer.trainers.trainer - INFO - Epoch 1, Step 1: loss 6.1567, lr 0.000667, tokens/s 33631.53</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,022 - hyformer.trainers.trainer - INFO - Epoch 1, Step 1: loss 6.1567, lr 0.000667, tokens/s 33631.53</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,022 - hyformer.trainers.trainer - INFO - Epoch 1, Step 1: loss 6.1567, lr 0.000667, tokens/s 33631.53</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,022 - hyformer.trainers.trainer - INFO - Epoch 1, Step 1: loss 6.1567, lr 0.000667, tokens/s 33631.53</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,022 - hyformer.trainers.trainer - INFO - Epoch 1, Step 1: loss 6.1567, lr 0.000667, tokens/s 33631.53</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,031 - hyformer.trainers.trainer - INFO - Epoch 1, Step 2: loss 6.1434, lr 0.000667, tokens/s 59545.96</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,031 - hyformer.trainers.trainer - INFO - Epoch 1, Step 2: loss 6.1434, lr 0.000667, tokens/s 59545.96</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,031 - hyformer.trainers.trainer - INFO - Epoch 1, Step 2: loss 6.1434, lr 0.000667, tokens/s 59545.96</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,031 - hyformer.trainers.trainer - INFO - Epoch 1, Step 2: loss 6.1434, lr 0.000667, tokens/s 59545.96</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:47,031 - hyformer.trainers.trainer - INFO - Epoch 1, Step 2: loss 6.1434, lr 0.000667, tokens/s 59545.96</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,817 - hyformer.trainers.trainer - INFO - Epoch 1, Step 3: loss 6.1258, lr 0.000667, tokens/s 33.21</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,817 - hyformer.trainers.trainer - INFO - Epoch 1, Step 3: loss 6.1258, lr 0.000667, tokens/s 33.21</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,817 - hyformer.trainers.trainer - INFO - Epoch 1, Step 3: loss 6.1258, lr 0.000667, tokens/s 33.21</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,817 - hyformer.trainers.trainer - INFO - Epoch 1, Step 3: loss 6.1258, lr 0.000667, tokens/s 33.21</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,817 - hyformer.trainers.trainer - INFO - Epoch 1, Step 3: loss 6.1258, lr 0.000667, tokens/s 33.21</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,835 - hyformer.trainers.trainer - INFO - Epoch 1: val_loss 6.0368</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,835 - hyformer.trainers.trainer - INFO - Epoch 1: val_loss 6.0368</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,835 - hyformer.trainers.trainer - INFO - Epoch 1: val_loss 6.0368</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,835 - hyformer.trainers.trainer - INFO - Epoch 1: val_loss 6.0368</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,835 - hyformer.trainers.trainer - INFO - Epoch 1: val_loss 6.0368</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,839 - hyformer.trainers.trainer - INFO -   - lm loss: 6.0368 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,839 - hyformer.trainers.trainer - INFO -   - lm loss: 6.0368 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,839 - hyformer.trainers.trainer - INFO -   - lm loss: 6.0368 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,839 - hyformer.trainers.trainer - INFO -   - lm loss: 6.0368 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"color: #0d6efd;\">2025-04-03 17:43:52,839 - hyformer.trainers.trainer - INFO -   - lm loss: 6.0368 (from 4 batches)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(train_dataset=train_dataset, val_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m test_metric \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m(test_dataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperplexity\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'test'"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "test_metric = trainer.test(test_dataset, 'perplexity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = trainer.create_loader(train_dataset, shuffle=True, tasks={'lm': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, model_input in enumerate(train_loader):\n",
    "    # Move batch to device - inputs is already a dict of tensors\n",
    "    model_input = {k: v.to(device, non_blocking=True) if isinstance(v, torch.Tensor) else v for k, v in model_input.items()}\n",
    "    model_output = model(**model_input)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model_output['logits'].detach().cpu()\n",
    "mask = model_output['attention_mask'].unsqueeze(-1).expand_as(logits).detach().cpu()\n",
    "logits[~mask] = -torch.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]],\n",
       "\n",
       "        [[ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         [ True,  True,  True,  ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[~mask] = -torch.inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.136662  ,  1.0592679 ,  0.3977642 , ...,  3.5987418 ,\n",
       "          0.5068621 ,  2.3434474 ],\n",
       "        [-1.3086665 ,  0.4904939 ,  0.73951775, ..., -0.09715027,\n",
       "          0.10324742,  0.677319  ],\n",
       "        [-1.0299996 , -0.40638733,  0.49864063, ...,  0.8964067 ,\n",
       "         -0.8524088 ,  1.2367059 ],\n",
       "        ...,\n",
       "        [-0.17828667, -0.6989492 , -1.1391791 , ..., -1.3364989 ,\n",
       "          1.4154167 , -1.4605953 ],\n",
       "        [-0.17870045, -0.6396375 , -1.1487352 , ..., -1.2919847 ,\n",
       "          1.4239221 , -1.404258  ],\n",
       "        [-0.18010461, -0.567212  , -1.155138  , ..., -1.2191597 ,\n",
       "          1.4638362 , -1.3483474 ]],\n",
       "\n",
       "       [[-1.136662  ,  1.0592679 ,  0.3977642 , ...,  3.5987418 ,\n",
       "          0.5068621 ,  2.3434474 ],\n",
       "        [-1.3086665 ,  0.4904939 ,  0.73951775, ..., -0.09715027,\n",
       "          0.10324742,  0.677319  ],\n",
       "        [-1.961201  ,  0.630399  ,  0.77966464, ...,  0.20175445,\n",
       "          0.9396163 , -0.0604695 ],\n",
       "        ...,\n",
       "        [-0.48047963, -0.53841233, -0.92524254, ...,  0.23249236,\n",
       "          0.8780139 , -1.2615306 ],\n",
       "        [-0.46889016, -0.45936444, -0.98351526, ...,  0.30461735,\n",
       "          0.93740803, -1.2099104 ],\n",
       "        [-0.45227122, -0.3659894 , -1.0349413 , ...,  0.3358692 ,\n",
       "          0.97321975, -1.1490289 ]],\n",
       "\n",
       "       [[       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        ...,\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf]],\n",
       "\n",
       "       [[       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        ...,\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [       -inf,        -inf,        -inf, ...,        -inf,\n",
       "                -inf,        -inf]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/groups/aih/hyformer/env/lib/python3.10/site-packages/scipy/special/_logsumexp.py:297: RuntimeWarning: invalid value encountered in subtract\n",
      "  out = tmp - out\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import log_softmax\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "log_probs = log_softmax(logits, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.1324854, -3.318623 , -1.8815334, -1.8131673, -3.3876677,\n",
       "        -3.1246696, -3.191782 , -3.0979633, -3.0450742, -2.2308354,\n",
       "        -2.330618 , -2.472324 , -3.6515033, -3.50948  , -3.3139763,\n",
       "        -2.6987703, -3.2547076, -3.4764345, -3.1284685, -3.9798079,\n",
       "        -3.127894 , -3.4546978, -1.6441965, -3.5386233, -2.89884  ,\n",
       "        -2.824465 , -2.4335928, -2.2494895, -2.1354132, -3.7622044,\n",
       "        -2.5043337, -3.1157641, -4.0375876, -2.037845 , -3.5541823,\n",
       "        -3.8744311, -3.2608833, -3.1368597, -3.5858393, -3.9428024,\n",
       "        -3.9238508, -3.8969798, -3.7878106, -3.6404438, -3.5714214,\n",
       "        -3.6126592, -3.6882749, -3.63384  , -3.5659509, -3.4978185,\n",
       "        -3.4211936, -3.3906994, -3.404259 , -3.4438875, -3.451629 ,\n",
       "        -3.4272156, -3.4222374, -3.4365067, -3.4236848, -3.3792446,\n",
       "        -3.3100119, -3.207237 , -3.1016018, -3.0563757, -3.0817776,\n",
       "        -3.1521232, -3.2167647, -3.2216198, -3.1543972, -3.0408382,\n",
       "        -2.9479885, -2.9263487],\n",
       "       [-3.1324854, -3.318623 , -3.7150881, -2.2042735, -2.4734075,\n",
       "        -3.1140552, -2.9531393, -3.2763417, -3.5397377, -3.580393 ,\n",
       "        -2.750996 , -2.9493287, -3.935048 , -2.7839875, -3.8138318,\n",
       "        -3.4266973, -3.2484014, -2.010666 , -3.1679611, -2.2333522,\n",
       "        -1.7146523, -2.2332811, -4.224667 , -2.4652221, -4.2741184,\n",
       "        -3.5313373, -3.6138453, -2.7298946, -3.7143455, -3.7772326,\n",
       "        -3.7038689, -3.4324794, -3.4231594, -3.5440795, -3.4340081,\n",
       "        -3.3139994, -3.3495615, -3.376297 , -3.155271 , -2.9614282,\n",
       "        -2.8847327, -2.8692975, -2.8698611, -2.848213 , -2.8657491,\n",
       "        -2.9917312, -3.0401998, -2.9476068, -2.9054441, -2.924198 ,\n",
       "        -2.9695718, -2.9419951, -2.9114182, -2.9570117, -3.011261 ,\n",
       "        -3.0689042, -3.0751758, -3.022158 , -2.9046443, -2.7859404,\n",
       "        -2.7416768, -2.7455146, -2.7404106, -2.7144632, -2.6733875,\n",
       "        -2.6209025, -2.5615206, -2.5457315, -2.608669 , -2.7074277,\n",
       "        -2.7812018, -2.826285 ],\n",
       "       [       nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan],\n",
       "       [       nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "log_probs.max(axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(logits, dim=-1).max(dim=-1).values\n",
    "\n",
    "\n",
    "\n",
    "if base == 'exp':\n",
    "    return torch.exp(-log_probs.nanmean(dim=-1))\n",
    "elif isinstance(base, float) or isinstance(base, int):\n",
    "    return base ** (-log_probs.nanmean(dim=-1))\n",
    "else:\n",
    "    raise ValueError(\"Invalid base type. Choose from 'exp' or float or int.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'training'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ictstr01/home/aih/adam.izdebski/projects/hyformer/hyformer/utils/decorators.py:20\u001b[0m, in \u001b[0;36minference.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m'\u001b[39m, model)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Save original mode and switch to eval\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m was_training \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\n\u001b[1;32m     21\u001b[0m module\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Disable grad and run inference\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'training'"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '</s>', '<pad>', '<unk>', '<mask>', '<lm>', '<cls>', '<mlm>']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[503, 504, 505, 506, 507, 508, 509, 510]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
