{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A recipe for finetuning a pre-trained Jointformer model on QED dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "\n",
    "from jointformer.configs.dataset import DatasetConfig\n",
    "from jointformer.configs.tokenizer import TokenizerConfig\n",
    "from jointformer.configs.model import ModelConfig\n",
    "from jointformer.configs.trainer import TrainerConfig\n",
    "\n",
    "from jointformer.utils.datasets.auto import AutoDataset\n",
    "from jointformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from jointformer.models.auto import AutoModel\n",
    "from jointformer.trainers.trainer import Trainer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "\n",
    "TARGET_LABEL = 'qed'\n",
    "REPOSITORY_DIR = '/home/adamizdebski/projects/jointformer'\n",
    "DATA_DIR = '/home/adamizdebski/files/data'\n",
    "OUTPUT_DIR = f'/home/adamizdebski/files/jointformer/results/jointformer/finetune/{TARGET_LABEL}'\n",
    "\n",
    "PATH_TO_DATASET_CONFIG   = f'/home/adamizdebski/projects/jointformer/configs/datasets/guacamol/{TARGET_LABEL}'\n",
    "PATH_TO_TOKENIZER_CONFIG = '/home/adamizdebski/projects/jointformer/configs/tokenizers/smiles'\n",
    "PATH_TO_MODEL_CONFIG = '/home/adamizdebski/projects/jointformer/configs/models/jointformer_test'\n",
    "PATH_TO_TRAINER_CONFIG = '/home/adamizdebski/projects/jointformer/configs/trainers/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(REPOSITORY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Datsaset\n",
    "\n",
    "dataset_config = DatasetConfig.from_config_file(PATH_TO_DATASET_CONFIG)\n",
    "tokenizer_config = TokenizerConfig.from_config_file(PATH_TO_TOKENIZER_CONFIG)\n",
    "\n",
    "train_dataset = AutoDataset.from_config(dataset_config, data_dir=DATA_DIR, split='train')\n",
    "val_dataset = AutoDataset.from_config(dataset_config, data_dir=DATA_DIR, split='val')\n",
    "test_dataset = AutoDataset.from_config(dataset_config, data_dir=DATA_DIR, split='test')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_config(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify dataset\n",
    "\n",
    "from rdkit import Chem\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def verify_dataset(dataset):\n",
    "    nonvalid_molecule_idx = []\n",
    "    nonvalid_target_idx = []\n",
    "\n",
    "    for idx, (smiles, target) in enumerate(tqdm(dataset)):\n",
    "        try:\n",
    "            Chem.MolFromSmiles(smiles)\n",
    "        except:\n",
    "            nonvalid_molecule_idx.append(idx)\n",
    "        if not torch.all(target == target):\n",
    "            nonvalid_target_idx.append(idx) \n",
    "    \n",
    "    return {\n",
    "        'nonvalid_molecule_idx': nonvalid_molecule_idx,\n",
    "        'nonvalid_target_idx': nonvalid_target_idx\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = ModelConfig.from_config_file(PATH_TO_MODEL_CONFIG)\n",
    "model = AutoModel.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Random seed set to 1337\n",
      "INFO: tokens per iteration set to: 256\n"
     ]
    }
   ],
   "source": [
    "trainer_config = TrainerConfig.from_config_file(PATH_TO_TRAINER_CONFIG)\n",
    "\n",
    "trainer = Trainer(\n",
    "    config=trainer_config,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    tokenizer=tokenizer\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Evaluation at step 0: train loss 6.3925, val loss 6.4002\n",
      "INFO: iter 100: loss 5.615761 on prediction task, lr 0.000600, time 259.22ms, mfu 0.00%\n",
      "INFO: Evaluation at step 200: train loss 4.6265, val loss 4.6266\n",
      "INFO: Validation loss: 4.6266\n",
      "INFO: Best validation loss: 1000000000.0000\n",
      "INFO: Checkpoint updated at iteration 200\n",
      "INFO: iter 200: loss 4.591779 on prediction task, lr 0.000300, time 8209.45ms, mfu 0.00%\n",
      "INFO: iter 300: loss 0.018068 on generation task, lr 0.000001, time 237.85ms, mfu 0.00%\n",
      "INFO: Evaluation at step 400: train loss 4.3897, val loss 4.4003\n",
      "INFO: Validation loss: 4.4003\n",
      "INFO: Best validation loss: 4.6266\n",
      "INFO: Checkpoint updated at iteration 400\n",
      "INFO: iter 400: loss 0.202759 on generation task, lr 0.000001, time 7853.10ms, mfu 0.00%\n",
      "INFO: iter 500: loss 4.326705 on prediction task, lr 0.000001, time 244.95ms, mfu 0.00%\n",
      "INFO: Evaluation at step 600: train loss 4.3938, val loss 4.3895\n",
      "INFO: Validation loss: 4.3895\n",
      "INFO: Best validation loss: 4.4003\n",
      "INFO: Checkpoint updated at iteration 600\n",
      "INFO: iter 600: loss 0.004322 on prediction task, lr 0.000001, time 7763.74ms, mfu 0.00%\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22091832756996155"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jointformer-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
