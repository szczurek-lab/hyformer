{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointformer Training\n",
    "\n",
    "This notebook shows how to train Jointformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "\n",
    "from jointformer.configs.dataset import DatasetConfig\n",
    "from jointformer.configs.tokenizer import TokenizerConfig\n",
    "from jointformer.configs.model import ModelConfig\n",
    "from jointformer.configs.trainer import TrainerConfig\n",
    "\n",
    "from jointformer.utils.datasets.auto import AutoDataset\n",
    "from jointformer.utils.tokenizers.auto import AutoTokenizer\n",
    "from jointformer.models.auto import AutoModel\n",
    "from jointformer.trainers.trainer import Trainer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory of the project\n",
    "\n",
    "REPOSITORY_DIR = '/home/adamizdebski/projects/jointformer'\n",
    "os.chdir(REPOSITORY_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "\n",
    "DATA_DIR = '/home/adamizdebski/files/data'\n",
    "OUTPUT_DIR = '/home/adamizdebski/files/jointformer/results/finetune'\n",
    "\n",
    "PATH_TO_DATASET_CONFIG   = '/home/adamizdebski/projects/jointformer/configs/datasets/guacamol/physchem'\n",
    "PATH_TO_TOKENIZER_CONFIG = '/home/adamizdebski/projects/jointformer/configs/tokenizers/smiles_separate_task_token'\n",
    "PATH_TO_MODEL_CONFIG = '/home/adamizdebski/projects/jointformer/configs/models/jointformer_v2'\n",
    "PATH_TO_TRAINER_CONFIG = '/home/adamizdebski/projects/jointformer/configs/trainers/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Datsaset\n",
    "\n",
    "dataset_config = DatasetConfig.from_config_file(PATH_TO_DATASET_CONFIG)\n",
    "tokenizer_config = TokenizerConfig.from_config_file(PATH_TO_TOKENIZER_CONFIG)\n",
    "\n",
    "train_dataset = AutoDataset.from_config(dataset_config, data_dir=DATA_DIR, split='train')\n",
    "val_dataset = AutoDataset.from_config(dataset_config, data_dir=DATA_DIR, split='val')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_config(tokenizer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 6.72M\n"
     ]
    }
   ],
   "source": [
    "# Init Jointformer\n",
    "\n",
    "model_config = ModelConfig.from_config_file(PATH_TO_MODEL_CONFIG)\n",
    "model = AutoModel.from_config(model_config, downstream_task=dataset_config.task_type, num_tasks=dataset_config.num_tasks, hidden_dim=256)\n",
    "# model.load_pretrained('ckpt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig({'model_name': 'JointformerV2', 'embedding_dim': 256, 'embedding_hidden_dim': 1024, 'num_heads': 8, 'num_local_heads': 8, 'head_dim': 32, 'num_layers': 8, 'bias': False, 'attention_dropout': None, 'feed_forward_dropout': None, 'prediction_dropout': None, 'layer_norm_eps': 1e-05, 'vocab_size': 596, 'max_seq_len': 128, 'prediction_task_type': None, 'num_prediction_tasks': None, 'num_physchem_tasks': 200, 'pretrained_filepath': None, 'predictor_hidden_size': None, 'predictor_dropout': None, 'predictor_num_heads': None, 'prediction_hidden_dim': 256, 'set_separate_task_tokens': None, 'flash_attention': True, 'dropout': 0.1, 'lambda_hparam': None, 'block_size': 128, 'n_embd': 256, 'n_layer': 8, 'n_head': 8, 'num_props': 200})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using fused AdamW: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer_config = TrainerConfig.from_config_file(PATH_TO_TRAINER_CONFIG)\n",
    "trainer = Trainer(\n",
    "    config=trainer_config,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    test_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._init_data_loaders()\n",
    "\n",
    "batch = next(iter(trainer.train_loader))\n",
    "batch.to('cuda')\n",
    "model.to('cuda')\n",
    "batch['task'] = 'physchem'\n",
    "outputs = model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 127])\n",
      "torch.Size([2, 127, 596])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([train_dataset[idx] for idx in range(2)], task='generation')\n",
    "inputs = inputs.to('cuda')\n",
    "model_outputs = model.get_loss(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_embeddings': tensor([[[-4.3458e-02, -6.9468e-04,  4.2362e-02,  ...,  2.1533e-02,\n",
       "           -6.0646e-02, -3.4861e-02],\n",
       "          [ 6.0578e-03, -4.7434e-02,  1.6648e-02,  ..., -7.4538e-03,\n",
       "            3.6801e-02,  1.7726e-02],\n",
       "          [-1.5884e-02, -8.6445e-03, -5.5961e-02,  ...,  1.6495e-02,\n",
       "            1.9452e-02, -1.6902e-02],\n",
       "          ...,\n",
       "          [ 2.8788e-02,  1.5539e-05,  5.0084e-02,  ..., -1.2208e-02,\n",
       "           -5.4630e-03,  1.4062e-02],\n",
       "          [ 1.9007e-03,  8.4405e-03,  1.3463e-02,  ..., -5.4869e-03,\n",
       "            2.1876e-02,  8.2266e-03],\n",
       "          [ 3.1826e-02,  2.3824e-03, -1.7455e-02,  ..., -9.0177e-03,\n",
       "            8.7530e-03,  4.6899e-02]],\n",
       " \n",
       "         [[-4.3458e-02, -6.9468e-04,  4.2362e-02,  ...,  2.1533e-02,\n",
       "           -6.0646e-02, -3.4861e-02],\n",
       "          [ 6.0578e-03, -4.7434e-02,  1.6648e-02,  ..., -7.4538e-03,\n",
       "            3.6801e-02,  1.7726e-02],\n",
       "          [ 3.9049e-02,  3.8860e-02, -1.8694e-02,  ..., -3.8230e-02,\n",
       "            2.5005e-02, -1.6724e-02],\n",
       "          ...,\n",
       "          [ 2.8788e-02,  1.5539e-05,  5.0084e-02,  ..., -1.2208e-02,\n",
       "           -5.4630e-03,  1.4062e-02],\n",
       "          [ 1.9007e-03,  8.4405e-03,  1.3463e-02,  ..., -5.4869e-03,\n",
       "            2.1876e-02,  8.2266e-03],\n",
       "          [ 3.1826e-02,  2.3824e-03, -1.7455e-02,  ..., -9.0177e-03,\n",
       "            8.7530e-03,  4.6899e-02]]], device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'embeddings': tensor([[[-0.9771,  1.0420, -0.6971,  ...,  1.5374, -1.1249, -0.6144],\n",
       "          [ 0.4173, -0.0699, -0.2298,  ...,  1.1151, -0.3546,  1.2022],\n",
       "          [-0.1939,  0.3214, -0.8914,  ..., -0.0154, -0.1379, -0.1688],\n",
       "          ...,\n",
       "          [ 1.9206,  1.4054,  0.3847,  ...,  0.5272, -0.5685, -0.0699],\n",
       "          [ 0.4297,  0.6051, -0.2229,  ..., -0.0588,  0.6277, -0.2607],\n",
       "          [ 1.6617,  0.0611, -1.5267,  ...,  0.0245,  0.2586, -0.8183]],\n",
       " \n",
       "         [[-1.1868,  0.3865, -0.8856,  ...,  1.9093, -1.0215, -1.9039],\n",
       "          [ 0.0053, -0.2768, -0.6169,  ...,  1.7274, -1.0741,  0.7358],\n",
       "          [ 0.2155,  0.5429, -2.5543,  ...,  0.0299, -0.7034, -0.4374],\n",
       "          ...,\n",
       "          [ 1.8818,  1.5685,  0.2419,  ...,  0.9611, -0.7160, -0.6196],\n",
       "          [ 0.9342,  0.3884, -0.8860,  ...,  0.4063,  0.8289,  0.3573],\n",
       "          [ 0.7060, -0.5473, -2.0597,  ...,  1.8053,  0.7888, -0.7820]]],\n",
       "        device='cuda:0', grad_fn=<NativeLayerNormBackward0>),\n",
       " 'logits': tensor([[[ 0.0940,  0.1308, -0.6652,  ...,  0.8454,  0.4527, -0.2400],\n",
       "          [ 0.3778,  0.2187,  0.1940,  ...,  0.1819, -0.1752, -0.0755],\n",
       "          [-0.0129,  0.1825, -0.3737,  ..., -0.0445,  0.1329,  0.2673],\n",
       "          ...,\n",
       "          [ 1.3207, -0.2830, -0.0629,  ...,  0.2327, -0.5292,  0.0744],\n",
       "          [ 0.7430, -0.2932,  0.0988,  ...,  0.2175, -0.1048,  0.1843],\n",
       "          [ 1.1430, -0.0695,  0.3197,  ...,  0.0051, -0.4150,  0.0805]],\n",
       " \n",
       "         [[-0.2408, -0.3624,  0.0530,  ...,  0.4881,  0.2475, -0.0212],\n",
       "          [ 0.2802, -0.1463,  0.4932,  ..., -0.0281, -0.1986, -0.1217],\n",
       "          [ 0.0521, -0.0714,  0.2612,  ..., -0.2984, -0.1196,  0.0879],\n",
       "          ...,\n",
       "          [ 0.6753, -0.3763, -0.1662,  ...,  0.2221, -0.5709, -0.1069],\n",
       "          [ 0.8384, -0.1395, -0.0249,  ...,  0.4949,  0.1140,  0.1707],\n",
       "          [ 1.0675,  0.0739,  0.2001,  ..., -0.2069, -0.1027,  0.1602]]],\n",
       "        device='cuda:0', grad_fn=<CloneBackward0>),\n",
       " 'loss': tensor(6.3293, device='cuda:0', grad_fn=<NllLossBackward0>)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jointformer-experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
