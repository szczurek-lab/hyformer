{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize RT class\n",
    "2. This contains the RT model \n",
    "3. Jan's generate method works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import csv\n",
    "from gt4sd.algorithms.conditional_generation.regression_transformer import  RegressionTransformer as RegressionTransformerGeneratorWrapper\n",
    "from gt4sd.algorithms.conditional_generation.regression_transformer import RegressionTransformerMolecules\n",
    "from rdkit import Chem\n",
    "import logging\n",
    "import os\n",
    "import pkgutil\n",
    "import tempfile\n",
    "import time\n",
    "from typing import List\n",
    "import pandas as pd \n",
    "import fcd\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "from guacamol.distribution_learning_benchmark import DistributionLearningBenchmark, DistributionLearningBenchmarkResult\n",
    "from guacamol.distribution_matching_generator import DistributionMatchingGenerator\n",
    "from guacamol.utils.data import get_random_subset\n",
    "from guacamol.utils.sampling_helpers import sample_valid_molecules\n",
    "from guacamol.assess_distribution_learning import DistributionMatchingGenerator\n",
    "from jointformer.models.base import BaseModel, SmilesEncoder\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from gt4sd.algorithms.conditional_generation.regression_transformer import (\n",
    "    RegressionTransformer, RegressionTransformerMolecules\n",
    ")\n",
    "\n",
    "\n",
    "from jointformer.models.regression_transformer import _load_regression_transformer_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplary model implementation\n",
    "\n",
    "from guacamol.assess_distribution_learning import DistributionMatchingGenerator\n",
    "from jointformer.models.base import BaseModel, SmilesEncoder\n",
    "from molecule_generation import load_model_from_directory, VaeWrapper\n",
    "from molecule_generation.models.moler_vae import MoLeRVae\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from molecule_generation.utils.model_utils import load_vae_model_and_dataset\n",
    "from molecule_generation.utils.moler_inference_server import _encode_from_smiles\n",
    "\n",
    "\n",
    "class Moler(BaseModel, DistributionMatchingGenerator, SmilesEncoder):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self._model: MoLeRVae = None\n",
    "        self._dataset = None\n",
    "        self._tokenizer = None\n",
    "        self._batch_size = None\n",
    "        self._temperature = None\n",
    "        self._top_k = None\n",
    "        self._device = None\n",
    "\n",
    "    def to_guacamole_generator(self, tokenizer, batch_size, temperature, top_k, device) -> DistributionMatchingGenerator:\n",
    "        self._tokenizer = tokenizer\n",
    "        self._batch_size = batch_size\n",
    "        self._temperature = temperature\n",
    "        self._top_k = top_k\n",
    "        self._device = device\n",
    "        return self\n",
    "    \n",
    "    def to_smiles_encoder(self, tokenizer, batch_size, device) -> SmilesEncoder:\n",
    "        self._tokenizer = tokenizer\n",
    "        self._batch_size = batch_size\n",
    "        self._device = device\n",
    "        return self\n",
    "\n",
    "    def generate(self, number_samples: int):\n",
    "        generated = []\n",
    "        with self._model as model:\n",
    "            for _ in tqdm(range(0, number_samples, self._batch_size), \"Generating samples\"):\n",
    "                samples = model.sample(self._batch_size)\n",
    "                generated.extend(samples)\n",
    "        return generated[:number_samples]\n",
    "\n",
    "    def encode(self, smiles: list[str]) -> np.ndarray:\n",
    "        rets = []\n",
    "        for i in tqdm(range(0, len(smiles), self._batch_size), \"Encoding samples\"):\n",
    "            batch = smiles[i:i+self._batch_size]\n",
    "            enc = _encode_from_smiles(self._dataset, self._model, batch)\n",
    "            rets.extend(enc)\n",
    "        return np.stack(rets, axis=0)\n",
    "\n",
    "    def load_pretrained(self, filename, *args, **kwargs):\n",
    "        self._dataset, self._model = load_vae_model_and_dataset(filename)\n",
    "        assert isinstance(self._model, MoLeRVae), self._model\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Transformer implementation\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "class RegressionTransformer(BaseModel, DistributionMatchingGenerator, SmilesEncoder):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self._model: RegressionTransformerGeneratorWrapper = None\n",
    "        self._dataset = None\n",
    "        self._tokenizer = None\n",
    "        self._batch_size = None\n",
    "        self._temperature = None\n",
    "        self._top_k = None\n",
    "        self._device = None\n",
    "        self._tolerence  = None\n",
    "        self._algorithm_version = None\n",
    "        self._search_strategy = None \n",
    "        self._target = None\n",
    "        self._fraction_to_mask = None\n",
    "\n",
    "\n",
    "    def to_guacamole_generator(\n",
    "            self, tokenizer, batch_size, temperature, top_k, device, tolerence,\n",
    "            target, search_strategy, fraction_to_mask, algorithm_version) -> DistributionMatchingGenerator:\n",
    "        self._tokenizer = tokenizer\n",
    "        self._batch_size = batch_size\n",
    "        self._temperature = temperature\n",
    "        self._top_k = top_k\n",
    "        self._device = device\n",
    "        self._tolerence  = tolerence \n",
    "        self._algorithm_version = algorithm_version\n",
    "        self._search_strategy =  search_strategy\n",
    "        self._target = target\n",
    "        self._fraction_to_mask = fraction_to_mask\n",
    "        return self\n",
    "    \n",
    "    def to_smiles_encoder(self, tokenizer, batch_size, device) -> SmilesEncoder:\n",
    "        self._tokenizer = tokenizer\n",
    "        self._batch_size = batch_size\n",
    "        self._device = device\n",
    "        return self\n",
    "\n",
    "    def _generate_single_example(self) -> str:\n",
    "        assert self._dataset is not None, \"Initialize the dataset prior to generation\"\n",
    "        seed_example, seed_property = random.sample(self._dataset, 1)[0]  # get the sampled example\n",
    "\n",
    "        generator = RegressionTransformerGeneratorWrapper(\n",
    "            configuration=RegressionTransformerMolecules(\n",
    "                algorithm_version=\"qed\",\n",
    "                search=\"sample\",\n",
    "                temperature=1.0, \n",
    "                tolerance=100,\n",
    "                sampling_wrapper={\n",
    "                    'property_goal': {'<qed>': seed_property}, \n",
    "                    'fraction_to_mask': 0.2\n",
    "                }),\n",
    "            target=seed_example)\n",
    "        generation = generator.sample(1)\n",
    "        return generation\n",
    "\n",
    "    def generate(self, number_samples: int):\n",
    "        generated = []\n",
    "        with self._model as model:\n",
    "            for _ in tqdm(range(0, number_samples, self._batch_size), \"Generating samples\"):\n",
    "                samples = model.sample(self._batch_size)\n",
    "                generated.extend(samples)\n",
    "        return generated[:number_samples]\n",
    "\n",
    "    def encode(self, smiles: list[str]) -> np.ndarray:\n",
    "        rets = []\n",
    "        for i in tqdm(range(0, len(smiles), self._batch_size), \"Encoding samples\"):\n",
    "            batch = smiles[i:i+self._batch_size]\n",
    "            enc = _encode_from_smiles(self._dataset, self._model, batch)\n",
    "            rets.extend(enc)\n",
    "        return np.stack(rets, axis=0)\n",
    "\n",
    "    def load_pretrained(self, filename, *args, **kwargs):\n",
    "        self._dataset = _load_regression_transformer_dataset(filename)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegressionTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = '/home/aih/gawade.pankhil/.conda/regression-transformer/data/qed/chembl_smiles_eval.txt'\n",
    "model.load_pretrained(FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gt4sd.algorithms.core:runnning RegressionTransformer with configuration=RegressionTransformerMolecules(algorithm_version='qed', search='sample', temperature=1.0, batch_size=8, tolerance=100.0, sampling_wrapper={'property_goal': {'<qed>': 'CCCN(CCC)c1c(C)nc(nc1OC)-c1c(OC)cccc1OC'}, 'fraction_to_mask': 0.2})\n",
      "INFO:gt4sd.algorithms.conditional_generation.regression_transformer.core:ensure artifacts for the application are present.\n",
      "INFO:gt4sd.s3:starting syncing\n",
      "INFO:gt4sd.s3:syncing complete\n",
      "INFO:gt4sd.s3:starting syncing\n",
      "INFO:gt4sd.s3:syncing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'InferenceBertTokenizer'.\n",
      "/home/aih/gawade.pankhil/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1132: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "/home/aih/gawade.pankhil/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/transformers/modeling_utils.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gt4sd.algorithms.conditional_generation.regression_transformer.implementation:Model restored from /home/aih/gawade.pankhil/.gt4sd/algorithms/conditional_generation/RegressionTransformer/RegressionTransformerMolecules/qed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "No registered converter was able to produce a C++ rvalue of type std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> > from this Python object of type float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_single_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 61\u001b[0m, in \u001b[0;36mRegressionTransformer._generate_single_example\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m         config \u001b[38;5;241m=\u001b[39m RegressionTransformerMolecules(\n\u001b[1;32m     50\u001b[0m         algorithm_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     51\u001b[0m         search\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# The alternative is 'greedy' but 'sample' is recommended for generative tasks\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m          }\n\u001b[1;32m     58\u001b[0m )\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;66;03m# Initialize the RegressionTransformer with the configuration\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m         qed_generator \u001b[38;5;241m=\u001b[39m \u001b[43mRegressionTransformerGeneratorWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed_example\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         generation \u001b[38;5;241m=\u001b[39m qed_generator\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/algorithms/conditional_generation/regression_transformer/core.py:87\u001b[0m, in \u001b[0;36mRegressionTransformer.__init__\u001b[0;34m(self, configuration, target)\u001b[0m\n\u001b[1;32m     84\u001b[0m configuration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_configuration(configuration)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# No validation/check on the target input here, since model is not yet loaded.\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type:ignore\u001b[39;49;00m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type:ignore\u001b[39;49;00m\n\u001b[1;32m     90\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/algorithms/core.py:110\u001b[0m, in \u001b[0;36mGeneratorAlgorithm.__init__\u001b[0;34m(self, configuration, target)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Targeted or untargeted generation.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    target: context or condition for the generation. Defaults to None.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    107\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunnning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with configuration=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfiguration\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m )\n\u001b[0;32m--> 110\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28msetattr\u001b[39m(\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m     ),\n\u001b[1;32m    117\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/algorithms/conditional_generation/regression_transformer/core.py:108\u001b[0m, in \u001b[0;36mRegressionTransformer.get_generator\u001b[0;34m(self, configuration, target)\u001b[0m\n\u001b[1;32m    106\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure artifacts for the application are present.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_artifacts \u001b[38;5;241m=\u001b[39m configuration\u001b[38;5;241m.\u001b[39mensure_artifacts()\n\u001b[0;32m--> 108\u001b[0m implementation: ConditionalGenerator \u001b[38;5;241m=\u001b[39m \u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_conditional_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresources_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_artifacts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m implementation\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m configuration\u001b[38;5;241m.\u001b[39msearch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreedy\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/algorithms/conditional_generation/regression_transformer/core.py:273\u001b[0m, in \u001b[0;36mRegressionTransformerMolecules.get_conditional_generator\u001b[0;34m(self, resources_path, context)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_conditional_generator\u001b[39m(\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m, resources_path: \u001b[38;5;28mstr\u001b[39m, context: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m    264\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChemicalLanguageRT:\n\u001b[1;32m    265\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Instantiate the actual generator implementation.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \n\u001b[1;32m    267\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m        instance with :meth:`generate_batch<gt4sd.algorithms.conditional_generation.regression_transformer.implementation.ChemicalLanguageRT.generate_batch>` method for targeted generation.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 273\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;241m=\u001b[39m \u001b[43mChemicalLanguageRT\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresources_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresources_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43msampling_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/algorithms/conditional_generation/regression_transformer/implementation.py:934\u001b[0m, in \u001b[0;36mChemicalLanguageRT.__init__\u001b[0;34m(self, resources_path, context, search, temperature, batch_size, tolerance, sampling_wrapper, device)\u001b[0m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msafely_determine_task(context)\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 934\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_sampling_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msampling_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_wrapper \u001b[38;5;241m=\u001b[39m sampling_wrapper\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/algorithms/conditional_generation/regression_transformer/implementation.py:688\u001b[0m, in \u001b[0;36mConditionalGenerator.validate_sampling_wrapper\u001b[0;34m(self, context, property_goal, fraction_to_mask, tokens_to_mask, substructures_to_mask, substructures_to_keep, text_filtering)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_input_molecule(context, MoleculeFormat\u001b[38;5;241m.\u001b[39mcopolymer)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_input_molecule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMoleculeFormat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmiles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed_molecule \u001b[38;5;241m=\u001b[39m context\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m property_goal \u001b[38;5;241m==\u001b[39m {}:\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/algorithms/conditional_generation/regression_transformer/implementation.py:985\u001b[0m, in \u001b[0;36mChemicalLanguageRT.validate_input_molecule\u001b[0;34m(self, sequence, input_type)\u001b[0m\n\u001b[1;32m    980\u001b[0m     _, idxs \u001b[38;5;241m=\u001b[39m validate_molecules(smis, input_type)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    982\u001b[0m     input_type \u001b[38;5;241m==\u001b[39m MoleculeFormat\u001b[38;5;241m.\u001b[39msmiles\n\u001b[1;32m    983\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m input_type \u001b[38;5;241m==\u001b[39m MoleculeFormat\u001b[38;5;241m.\u001b[39mcopolymer\n\u001b[1;32m    984\u001b[0m ):\n\u001b[0;32m--> 985\u001b[0m     _, idxs \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_molecules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idxs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    988\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe context \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/domains/materials/__init__.py:136\u001b[0m, in \u001b[0;36mvalidate_molecules\u001b[0;34m(pattern_list, input_type)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_molecules\u001b[39m(\n\u001b[1;32m    124\u001b[0m     pattern_list: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    125\u001b[0m     input_type: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[Any], List[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate molecules.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m        a tuple containing RDKit molecules and valid indexes.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMOLECULE_FORMAT_VALIDATOR_FACTORY\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/domains/materials/__init__.py:65\u001b[0m, in \u001b[0;36mvalidate_smiles\u001b[0;34m(smiles_list)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate molecules.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    a tuple containing RDKit molecules and valid indexes.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# generate molecules from SMILES\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m molecules \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     66\u001b[0m     Chem\u001b[38;5;241m.\u001b[39mMolFromSmiles(a_smiles, sanitize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m a_smiles \u001b[38;5;129;01min\u001b[39;00m smiles_list\n\u001b[1;32m     67\u001b[0m ]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# valid ids\u001b[39;00m\n\u001b[1;32m     69\u001b[0m valid_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     70\u001b[0m     index\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, molecule \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(molecules)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m molecule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m molecule \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/rtgt4sd/lib/python3.9/site-packages/gt4sd/domains/materials/__init__.py:66\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate molecules.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    a tuple containing RDKit molecules and valid indexes.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# generate molecules from SMILES\u001b[39;00m\n\u001b[1;32m     65\u001b[0m molecules \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 66\u001b[0m     \u001b[43mChem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMolFromSmiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_smiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a_smiles \u001b[38;5;129;01min\u001b[39;00m smiles_list\n\u001b[1;32m     67\u001b[0m ]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# valid ids\u001b[39;00m\n\u001b[1;32m     69\u001b[0m valid_ids \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     70\u001b[0m     index\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, molecule \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(molecules)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m molecule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m molecule \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: No registered converter was able to produce a C++ rvalue of type std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> > from this Python object of type float"
     ]
    }
   ],
   "source": [
    "model._generate_single_example()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.394, 'Nc1ccc(C=CC(=O)c2ccc(I)s2)cc1')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(model._dataset, 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import csv\n",
    "from gt4sd.algorithms.conditional_generation.regression_transformer import (\n",
    "    RegressionTransformer, RegressionTransformerMolecules\n",
    ")\n",
    "from rdkit import Chem\n",
    "import logging\n",
    "import os\n",
    "import pkgutil\n",
    "import tempfile\n",
    "import time\n",
    "from typing import List\n",
    "import pandas as pd \n",
    "import fcd\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "from guacamol.distribution_learning_benchmark import DistributionLearningBenchmark, DistributionLearningBenchmarkResult\n",
    "from guacamol.distribution_matching_generator import DistributionMatchingGenerator\n",
    "from guacamol.utils.data import get_random_subset\n",
    "from guacamol.utils.sampling_helpers import sample_valid_molecules\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# SMILES string for the target molecule\n",
    "#smi = \"CC(C#C)N(C)C(=O)NC1=CC=C(Cl)C=C1\"\n",
    "\n",
    "smi=\"CCCN(CCc1cccc(-c2ccccc2)c1)C(=O)C1OC(C(=O)O)=CC(N)C1NC(C)=O\"\n",
    "target_qed = 0.0\n",
    "target_esol = -3.53\n",
    "\n",
    "# Configuration for the RegressionTransformerMolecules\n",
    "config = RegressionTransformerMolecules(\n",
    "    algorithm_version=\"qed\",\n",
    "    search=\"sample\",  # The alternative is 'greedy' but 'sample' is recommended for generative tasks\n",
    "    temperature=1.0, \n",
    "    tolerance=100,  # Percentage of tolerated deviation from the desired property value (here -3.53)\n",
    "    sampling_wrapper={\n",
    "        'property_goal': {'<qed>': target_qed}, \n",
    "        'fraction_to_mask': 0.2\n",
    "    }\n",
    ")\n",
    "\n",
    "# Initialize the RegressionTransformer with the configuration\n",
    "qed_generator = RegressionTransformer(\n",
    "    configuration=config, target=smi\n",
    ")\n",
    "\n",
    "generations = list(qed_generator.sample(10000))\n",
    "#generations = list(esol_generator.sample(1000))\n",
    "# Generate a unique identifier for the file names\n",
    "unique_id = uuid.uuid4()\n",
    "# Define the output file path\n",
    "output_file = f'generations_{unique_id}.csv'\n",
    "summary_file = f'output_summary_{unique_id}.txt'\n",
    "#output_file = 'generations_16.csv'\n",
    "\n",
    "# Write to the CSV file\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # If 'generations' is a list of strings, use the following\n",
    "    for generation in generations:\n",
    "        writer.writerow([generation])\n",
    "\n",
    "def load_smiles(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        smiles_list = [line.strip() for line in file]\n",
    "    return smiles_list\n",
    "\n",
    "reference_smiles = load_smiles('./RT/guacamol_v1_train.smiles')\n",
    "\n",
    "#generations = pd.read_csv('generations.csv')\n",
    "#generations = [ast.literal_eval(generation) for generation in generations]\n",
    "generated_molecules = [i for i ,j in generations]\n",
    "chemnet_model_filename = 'ChemNet_v0.13_pretrained.pt'\n",
    "sample_size=30000\n",
    "reference_molecules = get_random_subset(reference_smiles, sample_size, seed=42)\n",
    "\n",
    "def _load_chemnet():\n",
    "        \"\"\"\n",
    "        Load the ChemNet model from the file specified in the init function.\n",
    "\n",
    "        This file lives inside a package but to use it, it must always be an actual file.\n",
    "        The safest way to proceed is therefore:\n",
    "        1. read the file with pkgutil\n",
    "        2. save it to a temporary file\n",
    "        3. load the model from the temporary file\n",
    "        \"\"\"\n",
    "        model_bytes = pkgutil.get_data('fcd', chemnet_model_filename)\n",
    "        assert model_bytes is not None\n",
    "\n",
    "        tmpdir = tempfile.gettempdir()\n",
    "        model_path = os.path.join(tmpdir, chemnet_model_filename)\n",
    "\n",
    "        with open(model_path, 'wb') as f:\n",
    "            f.write(model_bytes)\n",
    "\n",
    "        return fcd.load_ref_model(model_path)\n",
    "chemnet = _load_chemnet()\n",
    "\n",
    "def _calculate_distribution_statistics( model, molecules: List[str]):\n",
    "        sample_std = fcd.canonical_smiles(molecules)\n",
    "        gen_mol_act = fcd.get_predictions(model, sample_std)\n",
    "\n",
    "        mu = np.mean(gen_mol_act, axis=0)\n",
    "        cov = np.cov(gen_mol_act.T)\n",
    "        return mu, cov\n",
    "mu_ref, cov_ref =_calculate_distribution_statistics(model=chemnet,molecules=reference_molecules)\n",
    "mu, cov = _calculate_distribution_statistics(model=chemnet, molecules=generated_molecules)\n",
    "FCD = fcd.calculate_frechet_distance(mu1=mu_ref, mu2=mu,\n",
    "                                             sigma1=cov_ref, sigma2=cov)\n",
    "score = np.exp(-0.2 * FCD)\n",
    "\n",
    "metadata = {\n",
    "            'number_reference_molecules': len(reference_molecules),\n",
    "            'number_generated_molecules': len(generated_molecules),\n",
    "            'FCD': FCD,\n",
    "            'score': score\n",
    "\n",
    "        }\n",
    "with open(summary_file, 'w') as f:\n",
    "    f.write(\"Configuration Details:\\n\")\n",
    "    for key, value in config.__dict__.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "    f.write(\"\\nMetadata:\\n\")\n",
    "    for key, value in metadata.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "print(f'Results have been saved to {summary_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "terminator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
