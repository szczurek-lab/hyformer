{
    "tokenizer": "SmilesTokenizerWithPrefix",
    "path_to_vocabulary": "data/vocabularies/deepchem.txt",
    "max_molecule_length": 128
  }
  