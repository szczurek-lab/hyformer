{
    "tokenizer_type": "SMILESRegexTokenizer",
    "path_to_vocabulary": "data/vocabularies/deepchem.txt"
  }
  