{
    "tokenizer_type": "SMILESTokenizer",
    "vocabulary_path": "data/vocabulary/smiles.txt"
  }  
